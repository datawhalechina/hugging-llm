{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGPTä½¿ç”¨æŒ‡å—â€”â€”æ¨ç†Reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æœ¬ç« ä¸å…¶ä»–ç« èŠ‚çš„ä¸åŒï¼Œä¸æ¶‰åŠå¤ªå¤šçš„ä»£ç ï¼Œæ›´å¤šæ˜¯è®ºæ–‡çš„è§£è¯»å’Œæ–¹æ³•çš„ä»‹ç»ï¼Œé‡Œé¢çš„æ–¹æ³•éƒ½æ˜¯é€šç”¨çš„ï¼Œä½†è¿™é‡Œä¸»è¦ä½¿ç”¨ChatGPTæ¥ä½œä¸ºæ¼”ç¤ºã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ä»€ä¹ˆæ˜¯æ¨ç†ï¼ˆReasoningï¼‰ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åœ¨åšå‡ºé€‰æ‹©æˆ–å¤„ç†é—®é¢˜æ—¶ï¼Œæ¨ç†æ˜¯é€šè¿‡ä½¿ç”¨åŸºäºæ–°çš„æˆ–ç°æœ‰ä¿¡æ¯çš„é€»è¾‘æ¥ç†æ€§åœ°è¯„ä»·äº‹ç‰©çš„èƒ½åŠ›ã€‚æ¨ç†ä½¿ä½ åœ¨å†³å®šæœ€ä½³æ–¹æ¡ˆæˆ–æœ€èƒ½æ»¡è¶³ä½ çš„ç›®æ ‡çš„æ–¹æ¡ˆä¹‹å‰ï¼Œèƒ½å¤Ÿå¹³è¡¡ä¸¤ä¸ªæˆ–å¤šä¸ªæ–¹æ¡ˆçš„ä¼˜ç‚¹å’Œç¼ºç‚¹ã€‚å®ƒè¿˜èƒ½å¸®åŠ©ä½ è§£å†³å›°éš¾ã€å¤„ç†ä¸ç¡®å®šæ€§ã€æ ¸å®ç´¢èµ”ï¼Œå¹¶ä»”ç»†è¯„ä¼°æƒ…å†µï¼Œä»¥ç¡®ä¿ä½ åšå‡ºçš„å†³å®šç¬¦åˆä½ çš„æœ€ä½³åˆ©ç›Š[[1](https://unacademy.com/content/cat/study-material/data-interpretation-and-logical-reasoning/types-of-reasoning/)]ã€‚æ¯”å¦‚ï¼šæœ€è¿‘ä½ æ‰“ç®—ä¹°ä¸€å°ç”µè„‘ï¼Ÿ å†³å®šä¹‹å‰ï¼Œé¦–å…ˆä½ ä¼šè€ƒè™‘ä½ çš„é¢„ç®—ï¼ŒæŸ¥çœ‹ä½ é¢„ç®—èŒƒå›´çš„äº§å“ï¼›å…¶æ¬¡å¦‚æœä½ è¿½æ±‚é¢œå€¼ï¼Œæ¥ä¸‹æ¥ä½ ä¼šè€ƒè™‘ç”µè„‘çš„å¤–è§‚ï¼Œå¦‚æœä½ è¿½æ±‚æ€§ä»·æ¯”ï¼Œä½ ä¼šæ›´å…³æ³¨ç”µè„‘çš„ç¡¬ä»¶ï¼Œæ¯”å¦‚CPUã€GPUã€å†…å­˜ç­‰ï¼›æ­¤å¤–è¿˜æœ‰ä½ çš„éœ€æ±‚ï¼ˆå­¦ä¹ orå·¥ä½œï¼‰ï¼Œæ—¶é—´ç´§è¿«æ€§ç­‰ç­‰ï¼Œç»¼åˆè€ƒè™‘å¤šä¸ªå› ç´ ï¼Œæœ€ç»ˆå¾—å‡ºä¸€ä¸ªæœ€åˆé€‚çš„æ–¹æ¡ˆã€‚è¿™æ˜¯äººç±»çš„ä¸€é¡¹å®è´µçš„æŠ€èƒ½ï¼Œåœ¨äººç±»çš„ç”Ÿæ´»ä¸­æ‹¥æœ‰å¹¿æ³›çš„åº”ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/logical-reasoning-overview.jpg)\n",
    "\n",
    "æœ¬å›¾æ¥æºäº[*What are the 4 primary types of reasoning?* from Fibonicci.](https://www.fibonicci.com/logical-reasoning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å¸¸è§çš„æ¨ç†ç±»å‹ä¸»è¦åŒ…å«3ç§ï¼Œå³äºšé‡Œå£«å¤šå¾·åœ¨å…¬å…ƒå‰çš„ã€Šå‰åˆ†æç¯‡ã€‹ä¸­åˆ—ä¸¾äº†æ¨ç†çš„ä¸‰ç§ç±»å‹ï¼Œä¸ºæ¼”ç»ã€å½’çº³ä»¥åŠæº¯å›ã€‚åæ¥ï¼Œçš®å°”æ–¯åœ¨æ­¤åŸºç¡€ä¸Šæå‡ºäº†â€œæº¯å› æ¨ç†â€ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. æ¼”ç»æ¨ç†ï¼ˆDeductive Reasoningï¼‰[[2](https://www.fibonicci.com/logical-reasoning/)]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;ä¸€èˆ¬æ¥è¯´ï¼Œæ¼”ç»æ¨ç†æ˜¯æŒ‡ä½¿ç”¨ä¸€ç»„ç»™å®šçš„äº‹å®æˆ–æ•°æ®ï¼Œé€šè¿‡é€»è¾‘æ¨ç†æ¥æ¨å¯¼å‡ºå…¶ä»–äº‹å®ã€‚æ¼”ç»æ¨ç†ï¼Œä¹Ÿç§°ä¸ºä¸‰æ®µè®ºï¼Œé€šå¸¸çš„ç†è§£åŒ…æ‹¬ä¸¤ä¸ªå‰æï¼Œä¸€ä¸ªå¤§çš„å’Œä¸€ä¸ªå°çš„ï¼Œç„¶åä¸€ä¸ªé€»è¾‘ç»“è®ºï¼Œå¯ä»¥ç”¨æ¥è¯æ˜è¿™äº›æ–°çš„äº‹å®æ˜¯çœŸå®çš„ã€‚  \n",
    "\n",
    "&emsp;&emsp;ä¾‹å¦‚ï¼Œç»å…¸çš„ä¾‹å­ï¼š \n",
    "\n",
    "> å¤§å‰æï¼šäººç±»éƒ½æ˜¯å‡¡äºº  \n",
    "å°å‰æï¼šè‹æ ¼æ‹‰åº•æ˜¯äºº    \n",
    "ç»“è®ºï¼šè‹æ ¼æ‹‰åº•æ˜¯å‡¡äºº       \n",
    "                               \n",
    "&emsp;&emsp;åœ¨ \"è‹æ ¼æ‹‰åº•æ˜¯äºº\"ï¼ˆå°å‰æï¼‰çš„å…·ä½“æƒ…å†µä¸‹ï¼Œå¯¹ \"æ‰€æœ‰çš„äººéƒ½æ˜¯å‡¡äºº\"ï¼ˆå¤§å‰æï¼‰çš„ä¸€èˆ¬è§„åˆ™åº”ç”¨æ¼”ç»æ³•ï¼Œå¯ä»¥å¾—å‡ºç»“è®ºï¼š\"è‹æ ¼æ‹‰åº•æ˜¯å‡¡äºº\"ã€‚ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. å½’çº³æ¨ç†ï¼ˆInductive Reasoningï¼‰[[2](https://www.fibonicci.com/logical-reasoning/)]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å½’çº³æ¨ç†æ˜¯å¯»æ‰¾ä¸€ç§æ¨¡å¼æˆ–è¶‹åŠ¿ï¼Œç„¶åå¯¹å…¶è¿›è¡Œæ¦‚æ‹¬ã€‚å½“ä½ å¯¹ä¿¡æ¯è¿›è¡Œå½’çº³å’Œæ¨æ–­æ—¶ï¼Œä½ å¹¶ä¸ç¡®å®šè¿™ä¸€è¶‹åŠ¿æ˜¯å¦ä¼šç»§ç»­ä¸‹å»ï¼Œä½†ä½ å‡è®¾å®ƒä¼šç»§ç»­ä¸‹å»ã€‚å› æ­¤ï¼Œä½ å¹¶ä¸ç¡®å®šåŸºäºå½’çº³æ¨ç†çš„ç»“è®ºä¼šæ˜¯100%çš„çœŸå®ã€‚ \n",
    "        \n",
    "> ä¸€ä¸ªè‘—åçš„å‡è¯´æ˜¯ï¼š \"å¤©é¹…éƒ½æ˜¯ç™½çš„\"\n",
    "\n",
    "&emsp;&emsp;è¿™ä¸ªç»“è®ºæ˜¯åœ¨æ²¡æœ‰è§‚å¯Ÿåˆ°ä»»ä½•é»‘å¤©é¹…çš„æƒ…å†µä¸‹ä»å¤§é‡çš„è§‚å¯Ÿä¸­å¾—å‡ºçš„ï¼Œå› æ­¤åœ¨é€»è¾‘ä¸Šå‡è®¾é»‘å¤©é¹…ä¸å­˜åœ¨ã€‚æ‰€ä»¥ï¼Œå½’çº³æ¨ç†æ˜¯ä¸€ç§æœ‰é£é™©çš„é€»è¾‘æ¨ç†å½¢å¼ï¼Œå› ä¸ºä»å¤©é¹…çš„ä¾‹å­æ¥çœ‹ï¼Œå¦‚æœå‘ç°äº†ä¸€åªé»‘å¤©é¹…ï¼Œé‚£ä¹ˆç»“è®ºå°±å¾ˆå®¹æ˜“ä¸æ­£ç¡®äº†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åœ¨å®é™…èƒ½åŠ›æµ‹è¯•ä¸­ï¼Œå¦ä¸€ä¸ªå¸¸è§çš„å½’çº³æ¨ç†çš„ä¾‹å­æ˜¯æ•°å­—åºåˆ—ã€‚è¯•ç€ç¡®å®šæ¨¡å¼ï¼Œå½’çº³å’Œæ¨æ–­ï¼Œæ‰¾åˆ°è¯¥åºåˆ—çš„ä¸‹ä¸€ä¸ªæ•°å­—ã€‚\n",
    "\n",
    "> \"6, 9, 12, 15, ?\"\n",
    "        \n",
    "&emsp;&emsp;è¿™ä¸ªè¶‹åŠ¿çš„é€»è¾‘ç­”æ¡ˆä¼¼ä¹æ˜¯18ï¼Œä½†ä½ ä¸å¯èƒ½100%ç¡®å®šï¼Œä¹Ÿè®¸è¿™ä¸ªæ•°å­—ä»£è¡¨çš„æ˜¯å¤©æˆ–å°æ—¶æˆ–ä¸€äº›ä½ æ„æƒ³ä¸åˆ°çš„æ€ªäº‹ï¼Œè¿™å¯èƒ½å¯¼è‡´æ¨æ–­å‡ºçš„ç»“æœä¸åŒã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. æº¯å› æ¨ç†ï¼ˆAbductive reasoningï¼‰[[2](https://www.fibonicci.com/logical-reasoning/)]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æº¯å› æ¨ç†ä¸å½’çº³æ¨ç†æœ‰äº›ç±»ä¼¼ã€‚å®ƒæœ€æ—©æ˜¯ç”±â€œçŒœæµ‹â€ä¸€è¯å¼•å…¥çš„ï¼Œå› ä¸ºè¿™é‡Œå¾—å‡ºçš„ç»“è®ºæ˜¯åŸºäºæ¦‚ç‡çš„ã€‚åœ¨å½’çº³æ¨ç†ä¸­ï¼Œäººä»¬å‡å®šæœ€åˆç†çš„ç»“è®ºä¹Ÿæ˜¯æ­£ç¡®çš„ã€‚ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;ä¾‹å¦‚ï¼š\n",
    "\n",
    "> å¤§å‰æï¼šç½å­é‡Œè£…æ»¡äº†é»„è‰²çš„å¼¹ç    \n",
    "å°å‰æï¼šé²å‹ƒæ‰‹é‡Œæœ‰ä¸€é¢—é»„è‰²çš„å¼¹ç    \n",
    "ç»“è®ºï¼šé²å‹ƒæ‰‹ä¸­çš„é»„è‰²å¼¹ç æ˜¯ä»ç½å­é‡Œæ‹¿å‡ºæ¥çš„ã€‚  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;é€šè¿‡æº¯å› æ¨ç†ï¼Œé²å‹ƒä»ç½å­é‡Œæ‹¿èµ°é»„è‰²å¼¹ç çš„å¯èƒ½æ€§æ˜¯åˆç†çš„ï¼Œç„¶è€Œè¿™çº¯ç²¹æ˜¯åŸºäºæ¨æµ‹ã€‚é»„è‰²å¼¹ç å¯èƒ½æ˜¯ä»»ä½•äººé€ç»™é²å‹ƒçš„ï¼Œä¹Ÿå¯èƒ½æ˜¯é²å‹ƒåœ¨å•†åº—é‡Œä¹°çš„é»„è‰²å¼¹ç ã€‚å› æ­¤ï¼Œä»â€œè£…æ»¡é»„è‰²å¤§ç†çŸ³çš„ç½å­â€çš„è§‚å¯Ÿä¸­æ¨æ–­å‡ºé²å‹ƒæ‹¿èµ°äº†é»„è‰²å¤§ç†çŸ³ï¼Œå¯èƒ½ä¼šå¯¼è‡´ä¸€ä¸ªé”™è¯¯çš„ç»“è®ºã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/major-exteriors-of-brain.png)\n",
    "\n",
    "&emsp;&emsp;æœ¬å›¾æ¥æºäºï¼š[*What part of the brain is used in reasoning?* from How The Brain Learns](https://perpustakaan.gunungsitolikota.go.id/uploaded_files/temporary/DigitalCollection/ZDdhMTYzZDY2OWJjYmU3OWRlYTk3MDVhZDllYjQ5MjhmNDFmNmMxNQ==.pdf)\n",
    "\n",
    "&emsp;&emsp;ä»ä¸Šè¿°æ¨ç†æ¥çœ‹ï¼Œäººè„‘çš„å¤§è„‘çš®å±‚å¯¹è®¸å¤šè®¤çŸ¥å’Œæ„Ÿè§‰åŠŸèƒ½éƒ½è‡³å…³é‡è¦ï¼Œäººç±»æ¨ç†çš„è¿‡ç¨‹å’Œå¤§è„‘çš®å±‚çš„æ´»åŠ¨å¯†åˆ‡ç›¸å…³ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Modelï¼ŒLLMï¼‰å‘å±•è¿…é€Ÿï¼Œ100Bç”šè‡³æ›´å¤§å‚æ•°è§„æ¨¡çš„è¯­è¨€æ¨¡å‹å‡ºç°ï¼Œå®ƒä»¬å·²ç»åœ¨æƒ…æ„Ÿåˆ†æå’Œæœºå™¨ç¿»è¯‘ç­‰ä»»åŠ¡ä¸Šå–å¾—äº†ååˆ†ä¼˜å¼‚çš„è¡¨ç°ã€‚ç‰¹åˆ«çš„ï¼Œå»å¹´12æœˆChatGPTæ¨ªç©ºå‡ºä¸–ï¼Œå‡­å€Ÿå…¶å¼ºå¤§çš„èƒ½åŠ›å’Œæ™®éçš„é€‚ç”¨æ€§ç›´æ¥ç ´åœˆï¼Œå¼•èµ·äº†å„è¡Œå„ä¸šçš„äººç¾¤å…³æ³¨ã€‚ChatGPTæ˜¯ç”Ÿæˆå¼é¢„è®­ç»ƒ Transformerï¼ˆGPTï¼‰è¯­è¨€ç³»åˆ—æ¨¡å‹ä¸­çš„ä¸€ä¸ªæˆå‘˜ã€‚OpenAIåœ¨GPT-3æ”¹è¿›ç‰ˆâ€œGPT-3.5â€ä¸Šè¿›è¡Œå¾®è°ƒå¾—åˆ°çš„ã€‚ChatGPTæ‹¥æœ‰éå¸¸å¼ºå¤§çš„èƒ½åŠ›ï¼Œç”šè‡³æœ‰ç ”ç©¶è€…å‘ç°ChatGPTèƒ½å¤Ÿä»¥9å²å„¿ç«¥çš„èƒ½åŠ›é€šè¿‡æ€ç»´ç†è®ºæµ‹è¯•ã€‚é‚£ä¹ˆï¼ŒChatGPTæœ‰å¤šå¼ºå¤§å‘¢ï¼Ÿå®ƒåœ¨æ¨ç†è¿™ç±»ä»»åŠ¡ä¸Šæœ‰ç€æ€æ ·çš„è¡¨ç°å‘¢ï¼Ÿæœ‰æ²¡æœ‰æ–¹æ³•èƒ½è¿›ä¸€æ­¥æ¿€å‘æˆ–æ˜¯å¢å¼ºå…¶å¤„ç†å¤æ‚ä»»åŠ¡çš„èƒ½åŠ›ï¼ŸChatGPTè¿™ç§ç”Ÿæˆæ¨¡å‹æ˜¯å¦å…·æœ‰å¤§è„‘çš„åŠŸæ•ˆå‘¢ï¼Ÿä¸åŒåŠŸèƒ½åŒºæ˜¯å¦‚ä½•åˆ’åˆ†å‘¢ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;ä¸‹é¢æˆ‘å°†ç®€å•åœ°ä½¿ç”¨ChatGPTå›ç­”ä¸€ä¸ªé—®é¢˜ï¼ˆç¬¬2èŠ‚ï¼‰ï¼Œç„¶åç®€å•æµ‹è¯•ä¸€ä¸‹ChatGPTé¢å¯¹ä¸‰ä¸ªå¸¸è§çš„æ¨ç†ä»»åŠ¡çš„è¡¨ç°ï¼ˆç¬¬3èŠ‚ï¼‰ï¼Œåˆ©ç”¨ChatGPTçš„æ¨ç†èƒ½åŠ›æ›´å¥½åœ°å®Œæˆç°æœ‰ä»»åŠ¡ï¼ˆç¬¬4èŠ‚ï¼‰ï¼ŒChatGPTã€GPT4çš„æ¨ç†èƒ½åŠ›çš„å°ç»“ï¼ˆç¬¬5èŠ‚ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. å¯¼å…¥ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the OpenAI Python library for calling the OpenAI API\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# openai.api_key = \"å¡«å…¥ä¸“å±çš„API key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Chatgptä¸€ä¸ªå¯¹è¯çš„APIè°ƒç”¨åŒ…å«ä¸¤ä¸ªå¿…è¦çš„è¾“å…¥ï¼š\n",
    "\n",
    "- model: ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼ˆä¾‹å¦‚ï¼šgpt-3.5-turbo, gpt-4, gpt-4-0314ï¼‰ã€‚æœ¬æ–‡å†™ä½œä¹‹åˆï¼ŒOpenAIå¹¶æœªå…¬å¸ƒgpt-4, gpt-4-0314ï¼Œä¸ºæµ‹è¯•æ–¹ä¾¿ï¼Œç»“æœå‡ä¸ºgpt-3.5-turboï¼ˆä¹Ÿå°±æ˜¯æˆ‘ä»¬æœ€å¸¸ç”¨çš„ChatGPTçš„ç‰ˆæœ¬ï¼‰çš„è¾“å‡ºã€‚\n",
    "- message: ä¸€ä¸ªæ¶ˆæ¯å¯¹è±¡çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå¯¹è±¡æœ‰ä¸¤ä¸ªå¿…è¦çš„å­—æ®µï¼š\n",
    "    - role: ä¿¡ä½¿çš„è§’è‰²ï¼ŒåŒ…æ‹¬ï¼šsystemã€userï¼Œor assistant)\n",
    "    - content: ä¿¡æ¯çš„å†…å®¹ï¼Œä¾‹å¦‚: ç»™æˆ‘å†™ä¸€é¦–ç¾ä¸½çš„è¯—"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å…¶ä¸­ï¼Œæ¶ˆæ¯ä¹Ÿå¯ä»¥åŒ…å«ä¸€ä¸ªå¯é€‰çš„åç§°å­—æ®µï¼Œå®ƒç»™ä¿¡ä½¿ä¸€ä¸ªåå­—ã€‚ä¾‹å¦‚ï¼šexample-userã€Aliceã€BlackbeardBotã€‚åç§°ä¸­ä¸å¾—åŒ…å«ç©ºæ ¼ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;é€šå¸¸æƒ…å†µä¸‹ï¼Œå¯¹è¯ä¼šä»¥ä¸€ä¸ªå‘Šè¯‰åŠ©æ‰‹å¦‚ä½•è¡Œäº‹çš„ç³»ç»Ÿæ¶ˆæ¯å¼€å§‹ï¼Œç„¶åæ˜¯ç”¨æˆ·å’ŒåŠ©æ‰‹çš„æ¶ˆæ¯äº¤æ›¿å‡ºç°, ä½†å¯ä»¥ä¸éµå¾ªè¿™ç§æ ¼å¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-749WgDEJrldSgYkoyTLsPak41vt19 at 0x28d93ce3ea0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"content\": \"Orange who?\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1681224286,\n",
       "  \"id\": \"chatcmpl-749WgDEJrldSgYkoyTLsPak41vt19\",\n",
       "  \"model\": \"gpt-3.5-turbo-0301\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 3,\n",
       "    \"prompt_tokens\": 39,\n",
       "    \"total_tokens\": 42\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example OpenAI Python library request\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who's there?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Orange.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æµ‹è¯•ä¸€ä¸‹æ˜¯å¦æˆåŠŸäº†ï¼Œå¦‚æœè¿”å›äº†ä¸‹é¢çš„ç±»ä¼¼çš„ç»“æœï¼Œæ­å–œä½ æˆåŠŸäº†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "<OpenAIObject chat.completion id=chatcmpl-72sVLx6higzowFC3TjE5zLBU8k7TY at 0x2120f316400> JSON: {\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"finish_reason\": \"stop\",\n",
    "      \"index\": 0,\n",
    "      \"message\": {\n",
    "        \"content\": \"Orange who?\",\n",
    "        \"role\": \"assistant\"\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"created\": 1680920527,\n",
    "  \"id\": \"chatcmpl-72sVLx6higzowFC3TjE5zLBU8k7TY\",\n",
    "  \"model\": \"gpt-3.5-turbo-0301\",\n",
    "  \"object\": \"chat.completion\",\n",
    "  \"usage\": {\n",
    "    \"completion_tokens\": 3,\n",
    "    \"prompt_tokens\": 39,\n",
    "    \"total_tokens\": 42\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å“åº”å¯¹è±¡åŒ…æ‹¬ä¸‹é¢å‡ ä¸ªå­—æ®µï¼š\n",
    "\n",
    "- id: è¯·æ±‚çš„ID\n",
    "- object: è¿”å›çš„å¯¹è±¡çš„ç±»å‹ï¼ˆå¦‚chat.completionï¼‰\n",
    "- created: è¯·æ±‚çš„æ—¶é—´æˆ³\n",
    "- model: ç”¨äºç”Ÿæˆå›å¤çš„æ¨¡å‹çš„å…¨å\n",
    "- usage: ç”¨äºç”Ÿæˆå›å¤çš„tokenæ•°é‡ï¼ŒåŒ…æ‹¬æç¤ºã€å®Œæˆå’Œæ€»æ•°ã€‚\n",
    "- choices: å®Œæˆå¯¹è±¡çš„åˆ—è¡¨(åªæœ‰ä¸€ä¸ªï¼Œé™¤éä½ è®¾ç½®nå¤§äº1)\n",
    "    - message: ç”±æ¨¡å‹ç”Ÿæˆçš„æ¶ˆæ¯å¯¹è±¡ï¼ŒåŒ…æ‹¬è§’è‰²å’Œå†…å®¹\n",
    "    - finish_reason: ï¼šæ¨¡å‹åœæ­¢ç”Ÿæˆæ–‡æœ¬çš„åŸå› ï¼ˆè¦ä¹ˆæ˜¯åœæ­¢ï¼Œè¦ä¹ˆæ˜¯é•¿åº¦ï¼Œå¦‚æœè¾¾åˆ°max_tokensçš„é™åˆ¶ï¼‰\n",
    "    - index: é€‰æ‹©åˆ—è¡¨ä¸­çš„å®Œæˆåº¦çš„ç´¢å¼•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è‹¥åªéœ€è¦ç­”å¤ï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹ä»£ç ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é—®ChatGPTä¸€ä¸ªå…³äºDataWhaledçš„é—®é¢˜ï¼Œçœ‹çœ‹å›ç­”æ€ä¹ˆæ ·~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½œä¸ºAIè¯­è¨€æ¨¡å‹ï¼Œæˆ‘çŸ¥é“DataWhaleæ˜¯ä¸€ä¸ªå¼€æºçš„æ•°æ®ç§‘å­¦ç¤¾åŒºï¼Œè‡´åŠ›äºæ¨å¹¿æ•°æ®ç§‘å­¦å’Œäººå·¥æ™ºèƒ½çŸ¥è¯†ï¼Œä¸ºæ•°æ®ç§‘å­¦çˆ±å¥½è€…æä¾›å­¦ä¹ å’Œäº¤æµçš„å¹³å°ã€‚DataWhaleçš„æˆå‘˜æ¥è‡ªäºå„å¤§é«˜æ ¡å’ŒçŸ¥åä¼ä¸šï¼ŒåŒ…æ‹¬åä¸ºã€è…¾è®¯ã€ç™¾åº¦ç­‰ã€‚ä»–ä»¬é€šè¿‡ç»„ç»‡çº¿ä¸Šçº¿ä¸‹çš„å­¦ä¹ æ´»åŠ¨ã€åˆ†äº«è¯¾ç¨‹å’Œèµ„æºç­‰æ–¹å¼ï¼Œå¸®åŠ©æ›´å¤šäººå­¦ä¹ å’ŒæŒæ¡æ•°æ®ç§‘å­¦å’Œäººå·¥æ™ºèƒ½æŠ€æœ¯ã€‚\n"
     ]
    }
   ],
   "source": [
    "# example without a system message\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ä½ çŸ¥é“DataWhaleå—?\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å¯ä»¥çœ‹åˆ°ï¼ŒChatGPTçœŸçš„å¾ˆå‰å®³çš„ï¼ŒæŠŠDataWhaleçš„å±æ€§ã€ç›®æ ‡ã€æˆå‘˜ç»„æˆã€å·¥ä½œéƒ½åšåˆ°äº†éå¸¸å¥½çš„å›ç­”ğŸ‘ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å¥½äº†ï¼Œé¢„å¤‡å·¥ä½œç»“æŸäº†ï¼Œä¸‹é¢è®²è§£æ­£å¼å¼€å§‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æµ‹è¯•ChatGPTçš„æ¨ç†èƒ½åŠ›"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;è¿™ä¸€ç« èŠ‚ï¼Œé’ˆå¯¹å¸¸è§çš„æ¨ç†ä»»åŠ¡ï¼Œå¯¹ChatGPTè¿›è¡Œæµ‹è¯•ï¼Œçœ‹çœ‹ChatGPTçš„è¡¨ç°æ˜¯ä»€ä¹ˆæ ·å­çš„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 æ¼”ç»æ¨ç†ï¼ˆDeductive Reasoningï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è‹æ ¼æ‹‰åº•æ˜¯å‡¡äººã€‚\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"å¤§å‰æï¼šäººç±»éƒ½æ˜¯å‡¡äºº \\n \\\n",
    "                                     å°å‰æï¼šè‹æ ¼æ‹‰åº•æ˜¯äºº \\n \\\n",
    "                                     ç»“è®ºï¼š\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 å½’çº³æ¨ç†ï¼ˆInductive Reasoningï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "éƒ½æ˜¯ç”œçš„ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"è¥¿ç“œæ˜¯ç”œçš„ï¼Œé¦™ç“œæ˜¯ç”œçš„ï¼Œæ‰€ä»¥å«â€œç“œâ€çš„è”¬æœéƒ½åº”è¯¥ \\n \\\n",
    "                                     ç»“è®ºï¼š\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"6, 9, 12, 15, ? \\n \\\n",
    "                                     ç»“è®ºï¼š\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 æº¯å› æ¨ç†ï¼ˆAbductive reasoningï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ— æ³•ç¡®å®šï¼Œå› ä¸ºç½å­é‡Œè£…æ»¡äº†é»„è‰²çš„å¼¹ç ï¼Œé²å‹ƒæ‰‹é‡Œçš„é»„è‰²å¼¹ç å¯èƒ½æ¥è‡ªç½å­é‡Œï¼Œä¹Ÿå¯èƒ½æ¥è‡ªå…¶ä»–åœ°æ–¹ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"å¤§å‰æï¼šç½å­é‡Œè£…æ»¡äº†é»„è‰²çš„å¼¹ç   \\n \\\n",
    "                                    å°å‰æï¼šé²å‹ƒæ‰‹é‡Œæœ‰ä¸€é¢—é»„è‰²çš„å¼¹ç   \\n \\\n",
    "                                    é—®é¢˜ï¼šé²å‹ƒæ‰‹é‡Œçš„å¼¹ç æ¥è‡ªå“ªé‡Œï¼Ÿ\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”µæºçº¿è·¯å¯èƒ½æ¥è§¦ä¸å¥½ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"å¦‚æœç”µæºçº¿è·¯æ¥è§¦ä¸å¥½ï¼Œé‚£ä¹ˆæ—¥å…‰ç¯ç†„ç­ï¼›æ—¥å…‰ç¯ç†„ç­ï¼Œ\\n \\\n",
    "                                     æ‰€ä»¥: \"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 ä¸‰è€…ä¹‹é—´çš„å…³ç³»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;ä¸‹é¢ï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹çš®å°”æ–¯å¦‚ä½•ä½¿ç”¨â€œè±†å­å®ä¾‹â€æ¥é˜è¿°ä¸‰è€…çš„å…³ç³»ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. æ¼”ç»æ¨ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç™½è‰²çš„ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"è¿™ä¸ªè¢‹å­ä¸­çš„è±†å­éƒ½æ˜¯ç™½è‰²çš„ã€‚\\n \\\n",
    "                                     è¿™äº›è±†å­æ¥è‡ªè¿™ä¸ªè¢‹å­ã€‚\\n \\\n",
    "                                     è¿™äº›è±†å­æ˜¯\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. å½’çº³æ¨ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç™½è‰²çš„ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"è¿™äº›è±†å­æ¥è‡ªè¿™ä¸ªè¢‹å­ã€‚\\n \\\n",
    "                                     è¿™äº›è±†å­æ˜¯ç™½è‰²çš„ã€‚\\n \\\n",
    "                                     è¿™ä¸ªè¢‹å­ä¸­çš„è±†å­éƒ½æ˜¯\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. æº¯å› æ¨ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œå› ä¸ºä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰æåˆ°è±†å­çš„æ¥æºã€‚\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"è¿™ä¸ªè¢‹å­ä¸­çš„è±†å­éƒ½æ˜¯ç™½è‰²çš„ã€‚\\n \\\n",
    "                                     è¿™äº›è±†å­æ˜¯ç™½è‰²çš„ã€‚\\n \\\n",
    "                                     è¿™äº›è±†å­æ¥è‡ªå“ªé‡Œï¼Ÿ\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ— æ³•è¿›è¡Œæº¯å› æ¨ç†ï¼Œå› ä¸ºé¢˜ç›®ä¸­æ²¡æœ‰æä¾›è¶³å¤Ÿçš„ä¿¡æ¯ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"è¿™ä¸ªè¢‹å­ä¸­çš„è±†å­éƒ½æ˜¯ç™½è‰²çš„ã€‚\\n \\\n",
    "                                     è¿™äº›è±†å­æ˜¯ç™½è‰²çš„ã€‚\\n \\\n",
    "                                     è¿™äº›è±†å­æ¥è‡ªå“ªé‡Œï¼Ÿ è¯·è¿›è¡Œæº¯å› æ¨ç†\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/resoning.png)\n",
    "\n",
    "æœ¬å›¾æ¥æºäº[*æ¼”ç»ã€å½’çº³å’Œæº¯å› ä¹‹é—´çš„å…³ç³»*](https://new.qq.com/rain/a/20210327A02F4X00#:~:text=%E6%AF%94%E5%A6%82%E5%A5%B3%E6%9C%8B%E5%8F%8B%E7%94%9F%E6%B0%94%E4%BA%86,%E8%BF%99%E5%B0%B1%E6%98%AF%E6%BA%AF%E5%9B%A0%E6%8E%A8%E7%90%86%E3%80%82)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æœ¬èŠ‚ç®€å•è®¨è®ºäº†ChatGPTå¯¹äºä¸åŒç±»å‹çš„æ¨ç†é—®é¢˜çš„è¡¨ç°ï¼Œä¸Šé¢çš„ä¾‹å­æˆ‘ä»¬å¯ä»¥æ„Ÿè§‰åˆ°ï¼ŒChatGPTå¯ä»¥å¯¹æ¼”ç»ã€å½’çº³ç±»å‹çš„é—®é¢˜æœ‰å¾ˆå¥½çš„æ„ŸçŸ¥ï¼Œè€Œåœ¨æº¯å› æ¨ç†è¿™å—ä¼¼ä¹å¾ˆç¬¦åˆä¸€ä¸ªæ­£å¸¸äººçš„æ€ç»´ã€‚æœ€è¿‘LLMå‘å±•è¿…é€Ÿï¼Œä½†ç¬”è€…è®¤ä¸ºæœªæ¥ï¼ˆæ„šè§ï¼‰ï¼ŒLLMéœ€è¦è¿›ä¸€æ­¥å‘å±•ç”šè‡³æ˜¯AGIçš„çªç ´ï¼Œéƒ½éœ€è¦æå‡AIåœ¨æ¨ç†ç›¸å…³çš„èƒ½åŠ›ï¼Œçš®å°”æ–¯æ›¾æŒ‡å‡ºï¼š*â€œåªè¦æ˜¯å…³äºç§‘å­¦çš„è§‚å¿µï¼Œå°±éƒ½åˆ©ç”¨å¤–å±•ï¼ˆæº¯å› ï¼‰å¾—è€Œå¾—å‡ºçš„ï¼Œè€Œä¸”è¿™äº›è§‚å¿µéƒ½å¯ä»¥åˆ©ç”¨æ¼”ç»æ¥è¿›è¡ŒéªŒè¯â€*ã€‚å“ªä¸€å¤©ï¼ŒAIæ‹¥æœ‰äº†çœŸæ­£å®Œæ•´çš„æ¨ç†èƒ½åŠ›ï¼Œé‚£æ‰æ˜¯æˆ‘ä»¬çœŸæ­£æƒ³è±¡ä¸­çš„AIã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. è°ƒç”¨ChatPTçš„æ¨ç†èƒ½åŠ›"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;*äººè„‘çš„ç³»ç»Ÿåœ¨ç†Ÿæ‚‰æƒ…å¢ƒä¸­é‡‡å–çš„æ¨¡å¼æ˜¯ç²¾ç¡®çš„ï¼Œæ‰€ä½œå‡ºçš„çŸ­æœŸé¢„æµ‹æ˜¯å‡†ç¡®çš„ï¼Œé‡åˆ°æŒ‘æˆ˜æ—¶åšå‡ºçš„ç¬¬ä¸€ååº”ä¹Ÿæ˜¯è¿…é€Ÿä¸”åŸºæœ¬æ°å½“çš„ã€‚ç„¶è€Œï¼Œç³»ç»Ÿå­˜åœ¨æˆè§ï¼Œåœ¨å¾ˆå¤šç‰¹å®šçš„æƒ…å†µä¸‹ï¼Œè¿™ä¸€ç³»ç»Ÿæ˜“çŠ¯ç³»ç»Ÿæ€§é”™è¯¯ã€‚ä½ ä¼šå‘ç°è¿™ä¸ªç³»ç»Ÿæœ‰æ—¶å€™ä¼šå°†åŸæœ¬è¾ƒéš¾çš„é—®é¢˜ä½œç®€å•åŒ–å¤„ç†ï¼Œå¯¹äºé€»è¾‘å­¦å’Œç»Ÿè®¡å­¦é—®é¢˜ï¼Œå®ƒå‡ ä¹ä¸€æ— æ‰€çŸ¥ã€‚ â€”â€”ã€Šæ€è€ƒï¼Œå¿«ä¸æ…¢ã€‹*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;äººä»¬åœ¨ç”Ÿæ´»ä¸­ï¼Œé¢å¯¹ç®€å•çš„é—®é¢˜ï¼Œå¾ˆå¤šæ—¶å€™ä»…ä»…å‡­ç›´è§‰å¯ä»¥åº”å¯¹ï¼Œæ¯”å¦‚ $1 + 1 = 2$ï¼Œä½†å½“ä½ é¢å¯¹ä¸€ä¸ªå¾ˆå¤æ‚çš„äº‹æƒ…æ—¶ï¼Œè¿‡äºæ£˜æ‰‹ç”šè‡³ä¼šè®©ä½ è½¬ä¸è¿‡å¼¯æ¥ï¼Œè¿™ä¸ªæ—¶å€™ä½ å°±å¾—é™ä¸€ä¸‹æ¥ï¼Œä»”ç»†æ€è€ƒä¸€ä¸‹ï¼Œå¦‚ä½•è§£å†³ã€‚æ¯”å¦‚$48 \\times 2023 = \\text{?}$ï¼Œè¿™ä¸ªæ—¶å€™ä½ å¯èƒ½å°±æ²¡åŠæ³•ç›´æ¥åšå‡ºå›ç­”äº†ï¼Œä½ éœ€è¦å¿ƒç®—ä¸€ä¸‹ç”šè‡³æ‹¿å‡ºç¬”ï¼Œåœ¨è‰ç¨¿çº¸ä¸Šå†™ä¸‹$48 \\times 2023 = 40 \\times 2023 + 8 \\times 2023 = 80920 + 16184 = 97104$ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åŒæ ·ï¼Œå¦‚æœæˆ‘ä»¬è®©ChatGPTå›ç­”ä¸€ä¸ªçš„é—®é¢˜ï¼Œç®€å•ä¸€ç‚¹çš„ChatGPTç´§å‡­â€œç›´è§‰â€ï¼ˆè¿™é‡Œçš„ç›´è§‰å¯ä»¥ç†è§£å°±æ˜¯â€œä¸€ä¸‹å­â€å¾—åˆ°ï¼‰å°±å¯ä»¥å›ç­”ï¼Œä½†å½“é‡åˆ°ä¸€äº›è¾ƒä¸ºå¤æ‚çš„é—®é¢˜æ—¶ï¼ŒChatGPTä¸€ä¸‹å­å°±æ— æ³•å¾ˆå¥½çš„èƒœä»»äº†ï¼Œå¯èƒ½éœ€è¦ä¸€ä¸‹å­ï¼‹ä¸€ä¸‹å­ï¼Œä¸¤ä¸‹å­æ‰å¯ä»¥ï¼Œç”šè‡³éœ€è¦å¤šä¸‹å­æ‰èƒ½å®Œæˆã€‚æ€»ç»“ä¸‹æ¥å°±æ˜¯ï¼šé¢å¯¹å¤æ‚é—®é¢˜ï¼Œäººéœ€è¦æ€è€ƒï¼ŒChatGPTä¹Ÿä¸ä¾‹å¤–ï¼Œå®ƒä¹Ÿéœ€è¦æ€è€ƒã€‚å¦‚ä½•è®©ChatGPTä½¿ç”¨\"å¤šä¸‹å­\"çš„èƒ½åŠ›å‘¢ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å¯ä»¥ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢å…¥æ‰‹ï¼š\n",
    "\n",
    "1. é—®é¢˜ç»“æŸï¼ŒåŠ ä¸Šè®©å®ƒæ€è€ƒçš„é­”æ³•è¯­å¥ï¼Œæ¯”å¦‚ï¼š\"Let's think step by step.\" , è®©ChatGPTæ€è€ƒèµ·æ¥ \n",
    "2. ç»™ä¸€ä¸ªæˆ–è€…å‡ ä¸ªä¾‹å­ï¼Œè®©ChatGPTç±»æ¯”å­¦ä¹ ä¸€ä¸‹  \n",
    "3. è®©ChatGPTä½¿ç”¨å¤šç§æ€è·¯å›ç­”ï¼Œæœ€åç»¼åˆä¸€ä¸‹ï¼Œä¼˜ä¸­é€‰ä¼˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å¦‚æœå¤§å®¶å¯¹è¿™å—æ„Ÿå…´è¶£çš„è¯ï¼Œå¯ä»¥é˜…è¯»å…³äºæ€ç»´é“¾(Chain of Thoughtï¼ŒCOT)ç›¸å…³çš„paperï¼Œè¿™å—å·¥ä½œéå¸¸æœ‰æ„æ€çš„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/think.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 LLMæ¨ç†æ±‚é¼“åŠ±ï¼Œè¯·å‘Šè¯‰ChatGPTå»æ€è€ƒâ€”â€”Let's think step by step(Zero-shot-COT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;é›¶æ ·æœ¬æ€ç»´é“¾ï¼ˆZero-shot-CoTï¼‰çš„æç¤ºï¼Œæ¥è‡ªè®ºæ–‡ [Takeshi Kojima et al. in 2022](https://arxiv.org/abs/2205.11916)ï¼Œä»¥ä¸€ç§æå…¶ç®€å•çš„æ–¹å¼ï¼Œå³åœ¨ç­”æ¡ˆå‰åŠ ä¸Š \"Let's think step by step\"ï¼Œä¿ƒä½¿æ¨¡å‹è¿›è¡Œæ€è€ƒï¼Œè¿›è€Œæ¨ç†å‡ºæ­£ç¡®çš„ç­”æ¡ˆã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![zero-shot reasoning example](images/0-COT.png)\n",
    "\n",
    "æœ¬å›¾æ¥æºäº[Source: *Large Language Models are Zero-Shot Reasoners* by Takeshi Kojima et al. (2022).](https://arxiv.org/abs/2205.11916)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;ä¸€ä¸ªå®Œæ•´çš„Zero-shot-CoTè¿‡ç¨‹æ¶‰åŠä¸¤ä¸ªç‹¬ç«‹æ­¥éª¤ï¼šç¬¬ä¸€æ­¥ï¼Œè¿›è¡Œæ¨ç†ï¼›ç¬¬äºŒæ­¥ï¼Œæå–ç­”æ¡ˆã€‚é¦–å…ˆä½¿ç”¨ç¬¬ä¸€ä¸ªâ€œæ¨ç†â€æç¤ºï¼Œä»è¯­è¨€æ¨¡å‹ä¸­æå–å®Œæ•´çš„æ¨ç†è·¯å¾„ï¼Œç„¶åä½¿ç”¨ç¬¬äºŒä¸ªâ€œç­”æ¡ˆâ€æç¤ºï¼Œä»æ¨ç†æ–‡æœ¬ä¸­æå–æ­£ç¡®æ ¼å¼çš„ç­”æ¡ˆã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![zero-shot reasoning example](images/zero-shot_reasoners_fig2.png)\n",
    "\n",
    "æœ¬å›¾æ¥æºäº[Source: *Large Language Models are Zero-Shot Reasoners* by Takeshi Kojima et al. (2022).](https://arxiv.org/abs/2205.11916)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é—®é¢˜ï¼š\n",
    "\n",
    "&emsp;&emsp;ç”¨ä¸€åªæ°´æ¡¶è£…æ°´ï¼ŒæŠŠæ°´åŠ åˆ°åŸæ¥çš„2å€ï¼Œè¿æ¡¶é‡10åƒå…‹ï¼Œå¦‚æœæŠŠæ°´åŠ åˆ°åŸæ¥çš„5å€ï¼Œè¿æ¡¶é‡22åƒå…‹ã€‚æ¡¶é‡ŒåŸæœ‰æ°´å¤šå°‘åƒå…‹ï¼Ÿ\n",
    "\n",
    "ç­”æ¡ˆï¼š\n",
    "\n",
    "ï¼ˆ22-10ï¼‰Ã·ï¼ˆ5-2ï¼‰=12Ã·3=4ï¼ˆåƒå…‹ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç›´æ¥æé—®ChatGPTï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®¾åŸæ¥æ°´çš„é‡é‡ä¸ºxåƒå…‹ï¼Œåˆ™åŠ æ°´åæ°´çš„é‡é‡ä¸º2xåƒå…‹ï¼ŒåŠ æ°´å‰æ¡¶çš„é‡é‡ä¸ºyåƒå…‹ï¼Œåˆ™æœ‰ï¼š\n",
      "\n",
      "2x + y = y + 10   ï¼ˆåŠ æ°´åˆ°åŸæ¥çš„2å€ï¼Œè¿æ¡¶é‡10åƒå…‹ï¼‰\n",
      "\n",
      "5x + y = y + 22   ï¼ˆåŠ æ°´åˆ°åŸæ¥çš„5å€ï¼Œè¿æ¡¶é‡22åƒå…‹ï¼‰\n",
      "\n",
      "åŒ–ç®€å¾—ï¼š\n",
      "\n",
      "x = 6\n",
      "\n",
      "å› æ­¤ï¼Œæ¡¶é‡ŒåŸæœ‰æ°´6åƒå…‹ã€‚\n"
     ]
    }
   ],
   "source": [
    "# example without a system message\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ç”¨ä¸€åªæ°´æ¡¶è£…æ°´, æŠŠæ°´åŠ åˆ°åŸæ¥çš„2å€, è¿æ¡¶é‡10åƒå…‹, å¦‚æœæŠŠæ°´åŠ åˆ°åŸæ¥çš„5å€, è¿æ¡¶é‡22åƒå…‹ã€‚æ¡¶é‡ŒåŸæœ‰æ°´å¤šå°‘åƒå…‹?\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¯¹ç…§ç­”æ¡ˆï¼Œå¯ä»¥çœ‹åˆ°ChatGPTå¯¹è¿™ä¸ªé—®é¢˜å›ç­”é”™äº†ã€‚è®©æˆ‘ä»¬å‘ŠçŸ¥ChatGPTè¿›è¡Œæ¨ç†æ€è€ƒï¼Œè°ƒç”¨è¿™éƒ¨åˆ†èƒ½åŠ›è¯•è¯•ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨Zero-shot COTæ¨ç†:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç¬¬1æ­¥ï¼Œè·å–å®Œæ•´æ¨ç†æ­¥éª¤ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®¾åŸæ¥æ¡¶é‡Œçš„æ°´é‡xåƒå…‹ï¼Œæ¡¶æœ¬èº«é‡yåƒå…‹ï¼Œåˆ™æœ‰ï¼š\n",
      "\n",
      "ç¬¬ä¸€æ­¥ï¼šåŠ åˆ°åŸæ¥çš„2å€\n",
      "\n",
      "æ¡¶é‡Œçš„æ°´å˜æˆ2xåƒå…‹ï¼Œæ¡¶æœ¬èº«é‡y+10åƒå…‹ã€‚\n",
      "\n",
      "ç¬¬äºŒæ­¥ï¼šåŠ åˆ°åŸæ¥çš„5å€\n",
      "\n",
      "æ¡¶é‡Œçš„æ°´å˜æˆ5xåƒå…‹ï¼Œæ¡¶æœ¬èº«é‡y+22åƒå…‹ã€‚\n",
      "\n",
      "æ ¹æ®ä»¥ä¸Šä¸¤ä¸ªå¼å­ï¼Œæˆ‘ä»¬å¯ä»¥åˆ—å‡ºä¸€ä¸ªæ–¹ç¨‹ç»„ï¼š\n",
      "\n",
      "2x + y + 10 = 5x + y + 22\n",
      "\n",
      "åŒ–ç®€å¾—ï¼š\n",
      "\n",
      "3x = 12\n",
      "\n",
      "x = 4\n",
      "\n",
      "æ‰€ä»¥ï¼ŒåŸæ¥æ¡¶é‡Œçš„æ°´é‡4åƒå…‹ã€‚\n"
     ]
    }
   ],
   "source": [
    "# example without a system message\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ç”¨ä¸€åªæ°´æ¡¶è£…æ°´, æŠŠæ°´åŠ åˆ°åŸæ¥çš„2å€, è¿æ¡¶é‡10åƒå…‹, å¦‚æœæŠŠæ°´åŠ åˆ°åŸæ¥çš„5å€, è¿æ¡¶é‡22åƒå…‹ã€‚æ¡¶é‡ŒåŸæœ‰æ°´å¤šå°‘åƒå…‹? Let's think step by step.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç¬¬2æ­¥ï¼šæå–ç­”æ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ç”¨ä¸€åªæ°´æ¡¶è£…æ°´, æŠŠæ°´åŠ åˆ°åŸæ¥çš„2å€, è¿æ¡¶é‡10åƒå…‹, å¦‚æœæŠŠæ°´åŠ åˆ°åŸæ¥çš„5å€, è¿æ¡¶é‡22åƒå…‹ã€‚æ¡¶é‡ŒåŸæœ‰æ°´å¤šå°‘åƒå…‹? Let's think step by step.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"è®¾åŸæ¥æ¡¶é‡Œçš„æ°´é‡xåƒå…‹ï¼Œæ¡¶æœ¬èº«é‡yåƒå…‹ï¼Œåˆ™æœ‰ï¼š \\n \\\n",
    "                                        ç¬¬ä¸€æ­¥ï¼šåŠ åˆ°åŸæ¥çš„2å€ \\n \\\n",
    "                                        æ¡¶é‡Œçš„æ°´å˜æˆ2xåƒå…‹ï¼Œæ¡¶æœ¬èº«é‡y+10åƒå…‹ã€‚ \\n \\\n",
    "                                        ç¬¬äºŒæ­¥ï¼šåŠ åˆ°åŸæ¥çš„5å€ \\n \\\n",
    "                                        æ¡¶é‡Œçš„æ°´å˜æˆ5xåƒå…‹ï¼Œæ¡¶æœ¬èº«é‡y+22åƒå…‹ã€‚ \\n \\\n",
    "                                        æ ¹æ®ä»¥ä¸Šä¸¤ä¸ªå¼å­ï¼Œæˆ‘ä»¬å¯ä»¥åˆ—å‡ºä¸€ä¸ªæ–¹ç¨‹ç»„ï¼š \\n \\\n",
    "                                        2x + y + 10 = 5x + y + 22  \\n \\\n",
    "                                        åŒ–ç®€å¾—ï¼š \\n \\\n",
    "                                        3x = 12 \\n \\\n",
    "                                        x = 4 \\n \\\n",
    "                                        æ‰€ä»¥ï¼ŒåŸæ¥æ¡¶é‡Œçš„æ°´é‡4åƒå…‹ã€‚\"},\n",
    "        {\"role\": \"user\", \"content\": \"æ‰€ä»¥ï¼Œç­”æ¡ˆæ˜¯ï¼ˆé˜¿æ‹‰ä¼¯æ•°å­—ï¼‰ï¼š\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;é€šè¿‡ä¸Šé¢çš„ä¾‹å­å¤§å®¶ï¼Œå¯ä»¥çœ‹åˆ°ï¼ŒåŠ ä¸Š\"Let's think step by step\"çš„æç¤ºåï¼ŒChatGPTå¯¹è¿™é“æ•°å­¦é¢˜çš„è§£ç­”æ›´æœ‰é€»è¾‘æ€§äº†ï¼Œæ¨ç†çš„æ­¥éª¤ä¹Ÿæ›´åŠ æ¸…æ™°äº†ã€‚çœ‹ç€ä¸¤ä¸ªä¸ä¸€æ ·çš„ç­”æ¡ˆæœ‰æ²¡æœ‰é‚£ç§æ„Ÿè§‰â€”â€”å¼€å§‹çš„è§£ç­”å°±æ˜¯é‚£ç§è·³æ­¥çš„ï¼Œç¬¬äºŒç§æ˜¯è§„è§„çŸ©çŸ©æŒ‰ç…§è€å¸ˆæ•™çš„é€»è¾‘ï¼Œä¸€æ­¥ä¸€æ­¥è§£ç­”çš„ï¼Œæ ¹æ®ç»éªŒï¼Œä¸€æ­¥ä¸€æ­¥è§£ç­”æ­£ç¡®ç‡æ˜¯æ¯”è·³æ­¥è¦é«˜çš„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;åŸè®ºæ–‡ä¸­ä½¿ç”¨çš„GPT-3è¿™ä¸ªæ¨¡å‹è¿›è¡Œæµ‹è¯•çš„ï¼Œ\"Let's think step by step\"è¿™ä¸ªç®€å•çš„æŠ€å·§åœ¨MultiArithæ•°å­¦æ•°æ®é›†ä¸Šï¼Œå¯ä»¥ä½¿å‡†ç¡®ç‡ç¿»äº†ä¸¤ç•ªï¼Œä»18%ä¸Šå‡åˆ°79%ï¼æ­¤å¤–ï¼Œå¦‚ä¸‹è¡¨æ‰€ç¤ºï¼Œè¯¸å¦‚ï¼šFirst,(\\*)ã€Let's think about this logicallyç­‰æç¤ºéƒ½å¯ä»¥ç”¨æå‡LLMçš„æ¨ç†èƒ½åŠ›ï¼Œå¤§å®¶æ„Ÿå…´è¶£å¯ä»¥è¯•è¯•æ„å»ºè‡ªå·±çš„ä¾‹å­è¿›è¡Œå°è¯•ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![zero-shot reasoning example](images/zero-shot_reasoners_tab5.png)\n",
    "\n",
    "æœ¬å›¾æ¥æºäº[Source: *Large Language Models are Zero-Shot Reasoners* by Takeshi Kojima et al. (2022).](https://arxiv.org/abs/2205.11916)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### è¯¾åé—®é¢˜ï¼Œè¿™æ˜¯ä¸€ä¸ªæ•°å­¦é¢˜**\n",
    "\n",
    "é—®é¢˜ï¼š\n",
    "\n",
    "&emsp;&emsp;äº”å¹´çº§ä¸€ä¸­é˜Ÿå’ŒäºŒä¸­é˜Ÿè¦åˆ°è·å­¦æ ¡20åƒç±³çš„åœ°æ–¹å»æ˜¥æ¸¸ã€‚ç¬¬ä¸€ä¸­é˜Ÿæ­¥è¡Œæ¯å°æ—¶è¡Œ4åƒç±³ï¼Œç¬¬äºŒä¸­é˜Ÿéª‘è‡ªè¡Œè½¦ï¼Œæ¯å°æ—¶è¡Œ12åƒç±³ã€‚ç¬¬ä¸€ä¸­é˜Ÿå…ˆå‡ºå‘2å°æ—¶åï¼Œç¬¬äºŒä¸­é˜Ÿå†å‡ºå‘ï¼Œç¬¬äºŒä¸­é˜Ÿå‡ºå‘åå‡ å°æ—¶æ‰èƒ½è¿½ä¸Šä¸€ä¸­é˜Ÿï¼Ÿ\n",
    "\n",
    "ç­”æ¡ˆï¼š\n",
    "\n",
    "4Ã—2Ã·ï¼ˆ12-4ï¼‰= 4Ã—2Ã·8 = 1ï¼ˆæ—¶ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å¤§å®¶è¯•è¯•Zero-shot COTçš„æ–¹æ³•å§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example without a system message\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"  ï¼ŒLet's think step by step.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 ç»™å‡ ä¸ªä¾‹å­ï¼Œå‘Šè¯‰ChatGPTåº”è¯¥è¿™ä¹ˆæ€è€ƒâ€”â€”Chain of Thought Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ€ç»´é“¾(CoT)æç¤ºæ˜¯ä¸€ç§æœ€è¿‘å¼€å‘çš„æç¤ºæ–¹æ³•ï¼Œæ—¨åœ¨é¼“åŠ±å¤§è¯­è¨€æ¨¡å‹è§£é‡Šå…¶æ¨ç†è¿‡ç¨‹ã€‚ä¸‹å›¾æ˜¾ç¤ºäº† few shot standard promptï¼ˆå·¦ï¼‰ä¸ COT è¿‡ç¨‹ï¼ˆå³ï¼‰çš„æ¯”è¾ƒã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![chain of thought example](images/chain_of_thought_fig1.png)\n",
    "\n",
    "æœ¬å›¾æ¥æºäº[Source: *Chain of Thought Prompting Elicits Reasoning in Large Language Models* Jason Wei and Denny Zhou et al. (2022)](https://arxiv.org/pdf/2201.11903)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;CoTçš„ä¸»è¦æ€æƒ³æ˜¯ï¼Œé€šè¿‡å‘LLMå±•ç¤ºä¸€äº›å°‘é‡çš„å…¸èŒƒï¼Œåœ¨æ ·ä¾‹ä¸­è§£é‡Šæ¨ç†è¿‡ç¨‹ï¼Œå¤§è¯­è¨€æ¨¡å‹åœ¨å›ç­”æç¤ºæ—¶ä¹Ÿä¼šè·Ÿç€è¿›è¡Œæ¨ç†ã€‚\n",
    "\n",
    "&emsp;&emsp;ä¸‹é¢æˆ‘ä»¬é€šè¿‡ä»¥ä¸‹ä¾‹å­ï¼ˆæœ¬ä¾‹æ¥æºäº[å¢å¼ºChatGPTå›ç­”çš„é€»è¾‘æ€§](https://mp.weixin.qq.com/s?__biz=MzI1MTE3MTIwOQ==&mid=2247483750&idx=1&sn=ef559cfaadda6947e99ea0a16e36a69d&chksm=e9f65980de81d09616e4be6d7a46a39c1f878812b247b8a5a4dea7eceade827ea9491b10211d#rd)ï¼‰æ¥æ¼”ç¤ºä¸€ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¥‡æ•°æœ‰4ä¸ªï¼š3ã€35ã€96ã€923ã€‚\n",
      "å¶æ•°æœ‰6ä¸ªï¼š56ã€40ã€10ã€84ã€32ã€20ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"åœ¨è¿™äº›æ•°å­—3ã€56ã€35ã€96ã€40ã€10ã€84ã€923ã€32ã€20 ä¸­ï¼Œæœ‰å¤šå°‘ä¸ªå¥‡æ•°ï¼Œå¤šå°‘ä¸ªå¶æ•°ï¼Ÿ\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ­£ç¡®ç­”æ¡ˆæ˜¯ï¼š3ä¸ªå¥‡æ•°ï¼Œ7ä¸ªå¶æ•°ã€‚è¿™é‡Œä¸çŸ¥é“ä¸ºä»€ä¹ˆChatGPTæŠŠ96ä¹Ÿå½“æˆæ˜¯å¥‡æ•°äº†ï¼Œå¯èƒ½è§‰å¾—96å’Œ3ç›¸å…³ï¼Œå…¶ä»–å’Œä¸‰ç›¸å…³çš„éƒ½æ˜¯å¥‡æ•°ï¼Œæ‰€ä»¥æŠŠå®ƒä¹Ÿåˆ—ä¸ºå¥‡æ•°äº†ï¼Ÿï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;ä¸‹é¢åŠ ä¸Šï¼ŒLet's think step by stepï¼Œè¯•è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“ä»€ä¹ˆæ˜¯å¥‡æ•°å’Œå¶æ•°ã€‚å¥‡æ•°æ˜¯æŒ‡ä¸èƒ½è¢«2æ•´é™¤çš„æ•´æ•°ï¼Œè€Œå¶æ•°æ˜¯æŒ‡èƒ½è¢«2æ•´é™¤çš„æ•´æ•°ã€‚\n",
      "\n",
      "æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¯ä»¥é€ä¸ªæ£€æŸ¥è¿™äº›æ•°å­—ï¼Œçœ‹å®ƒä»¬æ˜¯å¦æ˜¯å¥‡æ•°æˆ–å¶æ•°ã€‚ \n",
      "\n",
      "3æ˜¯å¥‡æ•°ï¼Œå› ä¸ºå®ƒä¸èƒ½è¢«2æ•´é™¤ã€‚ \n",
      "\n",
      "56æ˜¯å¶æ•°ï¼Œå› ä¸ºå®ƒèƒ½è¢«2æ•´é™¤ï¼Œå³56Ã·2=28ã€‚ \n",
      "\n",
      "35æ˜¯å¥‡æ•°ï¼Œå› ä¸ºå®ƒä¸èƒ½è¢«2æ•´é™¤ã€‚ \n",
      "\n",
      "96æ˜¯å¶æ•°ï¼Œå› ä¸ºå®ƒèƒ½è¢«2æ•´é™¤ï¼Œå³96Ã·2=48ã€‚ \n",
      "\n",
      "40æ˜¯å¶æ•°ï¼Œå› ä¸ºå®ƒèƒ½è¢«2æ•´é™¤ï¼Œå³40Ã·2=20ã€‚ \n",
      "\n",
      "10æ˜¯å¶æ•°ï¼Œå› ä¸ºå®ƒèƒ½è¢«2æ•´é™¤ï¼Œå³10Ã·2=5ã€‚ \n",
      "\n",
      "84æ˜¯å¶æ•°ï¼Œå› ä¸ºå®ƒèƒ½è¢«2æ•´é™¤ï¼Œå³84Ã·2=42ã€‚ \n",
      "\n",
      "923æ˜¯å¥‡æ•°ï¼Œå› ä¸ºå®ƒä¸èƒ½è¢«2æ•´é™¤ã€‚ \n",
      "\n",
      "32æ˜¯å¶æ•°ï¼Œå› ä¸ºå®ƒèƒ½è¢«2æ•´é™¤ï¼Œå³32Ã·2=16ã€‚ \n",
      "\n",
      "20æ˜¯å¶æ•°ï¼Œå› ä¸ºå®ƒèƒ½è¢«2æ•´é™¤ï¼Œå³20Ã·2=10ã€‚ \n",
      "\n",
      "å› æ­¤ï¼Œè¿™äº›æ•°å­—ä¸­æœ‰5ä¸ªå¥‡æ•°å’Œ5ä¸ªå¶æ•°ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"åœ¨è¿™äº›æ•°å­—3ã€56ã€35ã€96ã€40ã€10ã€84ã€923ã€32ã€20 ä¸­ï¼Œæœ‰å¤šå°‘ä¸ªå¥‡æ•°ï¼Œå¤šå°‘ä¸ªå¶æ•°ï¼ŸLet's think step by step.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å¾ˆå¥‡æ€ªï¼Œè™½ç„¶è¿‡ç¨‹éƒ½åˆ—å¯¹äº†ï¼Œä½†æ˜¯ä¸çŸ¥ä¸ºä»€ä¹ˆæœ€åç»Ÿè®¡çš„æ—¶å€™ï¼ŒæŠŠè¿™ç»“æœç»Ÿè®¡é”™äº†ï¼ŒChatGPTä¹Ÿå¤ªç²—å¿ƒé©¬è™ï¼Œè¿™å‡†å¤‡æ•°å­¦è€å¸ˆæ•²è„‘å£³ã€‚ä¸è¿‡ï¼Œæ”¾åœ¨æ­£å¼è€ƒè¯•ä¸­ï¼Œç›¸æ¯”ç›´æ¥é—®ï¼Œæ­¥éª¤åˆ†è‡³å°‘å¾—åˆ°äº†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ—¢ç„¶â€œLet's think step by step.â€å¤±æ•ˆäº†ï¼Œéš¾é“ChatGPTçœŸçš„å°±æ— æ³•å¤„ç†è¿™ç§æƒ…å†µäº†å—ï¼Ÿæ”¾å¿ƒï¼Œä¸æ˜¯çš„ï¼Œæˆ‘ä»¬æ¢ä¸ªæ‰‹æ®µï¼Œç»™ChatGPTä¾‹å­å­¦ä¹ ä¸€ä¸‹ï¼Œ Make ChatGPT Great Again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆ‘ä»¬ä¸€ä¸ªä¸€ä¸ªæ•°ï¼š\n",
      "             1. 3æ˜¯å¥‡æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°0ä¸ªï¼Œå¥‡æ•°1ä¸ªï¼› \n",
      "             2. 56æ˜¯å¶æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°1ä¸ªï¼Œå¥‡æ•°1ä¸ªï¼› \n",
      "             3. 35æ˜¯å¥‡æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°1ä¸ªï¼Œå¥‡æ•°2ä¸ªï¼› \n",
      "             4. 96æ˜¯å¶æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°2ä¸ªï¼Œå¥‡æ•°2ä¸ªï¼› \n",
      "             5. 40æ˜¯å¶æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°3ä¸ªï¼Œå¥‡æ•°2ä¸ªï¼› \n",
      "             6. 10æ˜¯å¶æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°4ä¸ªï¼Œå¥‡æ•°2ä¸ªï¼› \n",
      "             7. 84æ˜¯å¶æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°5ä¸ªï¼Œå¥‡æ•°2ä¸ªï¼› \n",
      "             8. 923æ˜¯å¥‡æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°5ä¸ªï¼Œå¥‡æ•°3ä¸ªï¼› \n",
      "             9. 32æ˜¯å¶æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°6ä¸ªï¼Œå¥‡æ•°3ä¸ªï¼› \n",
      "             10. 20æ˜¯å¶æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°7ä¸ªï¼Œå¥‡æ•°3ä¸ªï¼› \n",
      "             æ‰€ä»¥ï¼Œä¸€å…±æœ‰7ä¸ªå¶æ•°ï¼Œ3ä¸ªå¥‡æ•°ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"åœ¨è¿™äº›æ•°å­— 38ã€31ã€89ã€224ç§ï¼Œæœ‰å¤šå°‘ä¸ªå¥‡æ•°ï¼Œå¤šå°‘ä¸ªå¶æ•°ï¼Ÿ.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"æˆ‘ä»¬ä¸€ä¸ªä¸€ä¸ªæ•°ï¼š\\n \\\n",
    "            1. 38æ˜¯å¶æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°1ä¸ªï¼Œå¥‡æ•°0ä¸ªï¼› \\n \\\n",
    "            2. 31æ˜¯å¥‡æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°1ä¸ªï¼Œå¥‡æ•°1ä¸ªï¼› \\n \\\n",
    "            3. 89æ˜¯å¥‡æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°1ä¸ªï¼Œå¥‡æ•°2ï¼› \\n \\\n",
    "            4. 224æ˜¯å¶æ•°ï¼Œæ­¤æ—¶ç´¯è®¡ï¼šå¶æ•°2ä¸ªï¼Œå¥‡æ•°2ä¸ªï¼› \\n \\\n",
    "            æ‰€ä»¥,ä¸€å…±æœ‰2ä¸ªå¶æ•°ï¼Œ2ä¸ªå¥‡æ•°ã€‚\"},\n",
    "        {\"role\": \"user\", \"content\": \"åœ¨è¿™äº›æ•°å­—3ã€56ã€35ã€96ã€40ã€10ã€84ã€923ã€32ã€20 ä¸­ï¼Œæœ‰å¤šå°‘ä¸ªå¥‡æ•°ï¼Œå¤šå°‘ä¸ªå¶æ•°ï¼Ÿ\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ€ç»´é“¾å·²è¢«è¯æ˜å¯¹äºç®—æœ¯ã€å¸¸è¯†å’Œç¬¦å·æ¨ç†ç­‰ä»»åŠ¡çš„ç»“æœæœ‰æ‰€æ”¹è¿›ã€‚ç‰¹åˆ«æ˜¯ï¼Œåœ¨GSM8KåŸºå‡†æµ‹è¯•ä¸Šï¼ŒPaLM 540Bé€šè¿‡æç¤ºè¾¾åˆ°äº†57%çš„å‡†ç¡®æ€§ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![chain of thought example](images/cot_s.png)\n",
    "\n",
    "æœ¬å›¾æ¥æºäº[Source: *Chain of Thought Prompting Elicits Reasoning in Large Language Models* Jason Wei and Denny Zhou et al. (2022)](https://arxiv.org/pdf/2201.11903)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 ä»»åŠ¡å¤ªéš¾ï¼Œæ‹†åˆ†ä¸€ä¸‹ï¼Œæ‰¾ä¸ªç®€å•çš„å»çªç ´â€”â€”Least to Most prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æœ€å°‘åˆ°æœ€å¤šæç¤ºè¿‡ç¨‹ (Least to Most prompting, LtM) æ˜¯æ€ç»´é“¾æç¤ºè¿‡ç¨‹(CoT prompting)çš„è¿›ä¸€æ­¥å‘å±•ã€‚å…·ä½“æ¥è¯´ï¼Œé¦–å…ˆå°†é—®é¢˜åˆ†è§£ä¸ºå­é—®é¢˜ï¼Œç„¶åé€ä¸ªè§£å†³ã€‚è¿™æ˜¯å—åˆ°é’ˆå¯¹å„¿ç«¥çš„ç°å®æ•™è‚²ç­–ç•¥çš„å¯å‘è€Œå‘å±•å‡ºçš„ä¸€ç§æŠ€æœ¯ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Least-to-most prompting](images/least-to-most_fig1.png)\n",
    "\n",
    "æœ¬å›¾æ¥æºäº[Source: *Least-to-most Prompting Enables Complex Reasoning in Large Language Models* by Denny Zhou et al. (2022)](https://arxiv.org/abs/2205.10625)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;ä¸æ€ç»´é“¾æç¤ºè¿‡ç¨‹ç±»ä¼¼ï¼Œéœ€è¦è§£å†³çš„é—®é¢˜é¦–å…ˆè¢«åˆ†è§£æˆä¸€ç»„å»ºç«‹åœ¨å½¼æ­¤ä¹‹ä¸Šçš„å­é—®é¢˜ã€‚åœ¨ç¬¬äºŒæ­¥ä¸­ï¼Œè¿™äº›å­é—®é¢˜è¢«é€ä¸ªè§£å†³ã€‚ä¸æ€ç»´é“¾ä¸åŒçš„æ˜¯ï¼Œå…ˆå‰å­é—®é¢˜çš„è§£å†³æ–¹æ¡ˆè¢«è¾“å…¥åˆ°æç¤ºä¸­ï¼Œä»¥å°è¯•è§£å†³ä¸‹ä¸€ä¸ªé—®é¢˜ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ç¤ºä¾‹ï¼šå­—ç¬¦è¿æ¥\n",
    "\n",
    "&emsp;&emsp;æˆ‘ä»¬å°è¯•é—®ä¸€ä¸ªç¨å¾®å¤æ‚çš„é—®é¢˜(æœ¬é—®é¢˜æ¥æºäº[Learn Promptingç½‘ç«™](https://learnprompting.org/docs/intermediate/least_to_most))ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. æ ‡å‡†çš„few-shot prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbbb\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Q: think, machine \\n \\\n",
    "                                     A: ke \\n \\\n",
    "                                            \\n \\\n",
    "                                     Q: learning, reasoning, generalization \\n \\\n",
    "                                     A: ggn \\n \\\n",
    "                                            \\n \\\n",
    "                                     Q: artificial, intelligence  \\n \\\n",
    "                                     A: le  \\n \\\n",
    "                                            \\n \\\n",
    "                                     Q: foo,bar,baz,blip  \\n \\\n",
    "                                     A:\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å³ä½¿æ˜¯ChatGPTï¼Œfew-shot ç¤ºä¾‹çš„è¡¨ç°ä¹Ÿéå¸¸ç³Ÿç³•ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. COTæ€ç»´é“¾è¿‡ç¨‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last letter of \"foo\" is \"o\". The last letter of \"bar\" is \"r\". The last letter of \"baz\" is \"z\". The last letter of \"blip\" is \"p\". So \"foo,bar,baz,blip\" is \"orzp\".\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Q: think, machine \\n \\\n",
    "                                     A: The last letter of \\\"think\\\" is \\\"k\\\". The last letter of \\\"machine\\\" is \\\"e\\\". So \\\"think, machine\\\" is \\\"ke\\\". \\n \\\n",
    "                                            \\n \\\n",
    "                                     Q: learning, reasoning, generalization \\n \\\n",
    "                                     A: The last letter of \\\"learning\\\" is \\\"g\\\". The last letter of \\\"reasoning\\\" is \\\"n\\\". The last letter of \\\"generalization\\\" is \\\"n\\\". So \\\"learning, reasoning, generalization\\\" is \\\"ggn\\\". \\n \\\n",
    "                                            \\n \\\n",
    "                                     Q: artificial, intelligence  \\n \\\n",
    "                                     A: The last letter of \\\"artificial\\\" is \\\"l\\\". The last letter of \\\"intelligence\\\" is \\\"e\\\". So \\\"artificial, intelligence\\\" is \\\"le\\\". \\n \\\n",
    "                                            \\n \\\n",
    "                                     Q: foo,bar,baz,blip  \\n \\\n",
    "                                     A:\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last letter of \"foo\" is \"o\". The last letter of \"bar\" is \"r\". The last letter of \"baz\" is \"z\". The last letter of \"blip\" is \"p\". The last letter of \"learn\" is \"n\". The last letter of \"prompting\" is \"g\". The last letter of \"world\" is \"d\". The last letter of \"shaking\" is \"g\". The last letter of \"event\" is \"t\". The last letter of \"dancefloor\" is \"r\". The last letter of \"prisma\" is \"a\". The last letter of \"giraffe\" is \"e\". So \"foo,bar,baz,blip,learn,prompting,world,shaking,event,dancefloor,prisma,giraffe\" is \"orzpngdgrae\".\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Q: think, machine \\n \\\n",
    "                                     A: The last letter of \\\"think\\\" is \\\"k\\\". The last letter of \\\"machine\\\" is \\\"e\\\". So \\\"think, machine\\\" is \\\"ke\\\". \\n \\\n",
    "                                            \\n \\\n",
    "                                     Q: learning, reasoning, generalization \\n \\\n",
    "                                     A: The last letter of \\\"learning\\\" is \\\"g\\\". The last letter of \\\"reasoning\\\" is \\\"n\\\". The last letter of \\\"generalization\\\" is \\\"n\\\". So \\\"learning, reasoning, generalization\\\" is \\\"ggn\\\". \\n \\\n",
    "                                            \\n \\\n",
    "                                     Q: artificial, intelligence  \\n \\\n",
    "                                     A: The last letter of \\\"artificial\\\" is \\\"l\\\". The last letter of \\\"intelligence\\\" is \\\"e\\\". So \\\"artificial, intelligence\\\" is \\\"le\\\". \\n \\\n",
    "                                            \\n \\\n",
    "                                     Q: foo,bar,baz,blip,learn,prompting,world,shaking,event,dancefloor,prisma,giraffe  \\n \\\n",
    "                                     A:\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ€ç»´é“¾çš„è¡¨ç°æ¯”æ ‡å‡†æç¤ºå¥½å¾—å¤šã€‚è¿™æ˜¯å› ä¸ºå®ƒç°åœ¨å…è®¸æ¨¡å‹è€ƒè™‘è‡ªå·±æå–æ¯ä¸ªå•è¯çš„æœ€åä¸€ä¸ªå­—æ¯ï¼Œå°†å¤æ‚æ€§é™ä½åˆ°åˆ†ç»„å·²ç»æ”¶é›†çš„å­—æ¯çš„è¡Œä¸ºã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•åœ¨æ›´é•¿çš„è¾“å…¥ä¸‹ä¹Ÿå¯èƒ½æ…¢æ…¢å‡ºç°é—®é¢˜ã€‚\n",
    "\n",
    "> \"foo,bar,baz,blip\" --> \"orzp\"  \n",
    "\"foo,bar,baz,blip,learn,prompting,world,shaking,*event*,dancefloor,prisma,giraffe\" --> \"orzpngdgrae\"\n",
    "\n",
    "&emsp;&emsp;å½“è¾“å…¥ä¸º4ä¸ªè¯æ—¶ï¼ŒChain of Thoughtå®Œå…¨å›ç­”æ­£ç¡®ï¼Œå½“è¾“å…¥å¢åŠ åˆ°12ä¸ªè¯çš„æ—¶å€™ï¼Œç»è¿‡åˆ†æè¿‡ç¨‹æåˆ°äº†eventè¿™ä¸ªè¯çš„æœ«å°¾å­—æ¯ä¸ºzï¼Œä½†ç»“æœå´å¿˜è®°è¾“å‡ºäº†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. LtM(å•ä¸€æç¤º)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;å…³äºä½¿ç”¨LtMï¼Œæˆ‘ä»¬é€šè¿‡é‡æ–°è¡¨è¿°å…ˆå‰ä¸²è”çš„ç»“æœæ¥å¢å¼ºæ€ç»´é“¾çš„æ¦‚å¿µã€‚è¿™ç§åšæ³•ä½¿å¾—æ¯ä¸ªæ­¥éª¤å˜å¾—ç®€å•ï¼Œå³æ¯æ¬¡åªéœ€è¦è¿æ¥ä¸€ä¸ªå­—ç¬¦ã€‚è¿™ç§æ–¹æ³•å¸¦æ¥äº†éå¸¸å¥½çš„æ•ˆæœï¼Œ12ä¸ªä¹ƒè‡³æ›´å¤šçš„è¯éƒ½èƒ½å¾—åˆ°æ­£ç¡®ç»“æœã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;è¿™ç§æ–¹æ³•çœ‹èµ·æ¥ä¸æ€ç»´é“¾éå¸¸ç›¸ä¼¼ï¼Œä½†åœ¨æ¦‚å¿µä¸Šå¤§æœ‰ä¸åŒã€‚åœ¨è¿™é‡Œï¼Œæ¯ä¸€æ­¥éƒ½å¼•å…¥äº†ä¸Šä¸€æ­¥è¿æ¥çš„ç»“æœã€‚ä¾‹å¦‚ï¼Œåœ¨â€œthink, machine, learningâ€çš„è¿™ä¸ªä¾‹å­ä¸­ï¼Œå®ƒä¸ä¼šå•ç‹¬è¿æ¥å­—ç¬¦â€œkâ€ï¼Œâ€œeâ€ï¼Œâ€œlâ€ï¼Œè€Œæ˜¯å…ˆè¿æ¥â€œkâ€å’Œâ€œeâ€ï¼Œç„¶åè¿æ¥â€œkeâ€å’Œâ€œlâ€ã€‚ç”±äºé‡æ–°å¼•å…¥äº†ä¸Šä¸€æ­¥çš„ç»“æœï¼Œæ¨¡å‹ç°åœ¨å¯ä»¥æ¨å¹¿åˆ°æ›´é•¿çš„é“¾ï¼Œå› ä¸ºå®ƒæ¯ä¸€æ­¥éƒ½å¸¦ç€å¢é‡ç»“æœï¼ŒåŒæ—¶å•æ­¥éª¤å†…åªéœ€è¦åšå¾ˆå°‘çš„å·¥ä½œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last letter of \"foo\" is \"o\". The last letter of \"bar\" is \"r\". The last letter of \"baz\" is \"z\". The last letter of \"blip\" is \"p\". The last letter of \"learn\" is \"n\". The last letter of \"prompting\" is \"g\". The last letter of \"world\" is \"d\". The last letter of \"shaking\" is \"g\". The last letter of \"event\" is \"t\". The last letter of \"dancefloor\" is \"r\". The last letter of \"prisma\" is \"a\". The last letter of \"giraffe\" is \"e\". Concatenating all these letters gives \"orzpngdgtrea\". So \"foo,bar,baz,blip,learn,prompting,world,shaking,event,dancefloor,prisma,giraffe\" is \"orzpngdgtrea\".\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Q: think, machine \\n \\\n",
    "                                     A: The last letter of \\\"think\\\" is \\\"k\\\". The last letter of \\\"machine\\\" is \\\"e\\\". Concatenating \\\"k\\\" and \\\"e\\\" gives \\\"ke\\\". So \\\"think, machine\\\" output \\\"ke\\\". \\n \\\n",
    "                                            \\n \\\n",
    "                                     Q: think, machine, learning \\n \\\n",
    "                                     A: \\\"think, machine\\\" outputs \\\"ke\\\". The last letter of \\\"learning\\\" is \\\"g\\\". Concatenating \\\"ke\\\" and \\\"g\\\" gives \\\"keg\\\". So \\\"think, machine, learning\\\" is \\\"keg\\\". \\n \\\n",
    "                                            \\n \\\n",
    "                                     Q: transformer, language \\n \\\n",
    "                                     A: The last letter of \\\"transformer\\\" is \\\"r\\\". The last letter of \\\"language\\\" is \\\"e\\\". Concatenating \\\"r\\\" and \\\"e\\\" gives \\\"re\\\". So \\\"transformer, language\\\" is \\\"re\\\". \\n \\\n",
    "                                            \\n \\\n",
    "                                     Q: transformer, language, vision \\n \\\n",
    "                                     A: \\\"transformer, language\\\" outputs \\\"re\\\". The last letter of \\\"vision\\\" is \\\"n\\\". Concatenating \\\"re\\\" and \\\"n\\\" gives \\\"ren\\\". So \\\"transformer, language, vision\\\" is \\\"ren\\\". \\n \\\n",
    "                                            \\n \\\n",
    "                                     Q: foo,bar,baz,blip,learn,prompting,world,shaking,event,dancefloor,prisma,giraffe  \\n \\\n",
    "                                     A:\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> COT : \"foo,bar,baz,blip,learn,prompting,world,shaking,*event*,dancefloor,prisma,giraffe\" --> \"orzpngdgrae\"  \n",
    "LtM : \"foo,bar,baz,blip,learn,prompting,world,shaking,event,dancefloor,prisma,giraffe\" --> \"orzpngdgtrea\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ ¹æ®ä¸Šè¿°çš„ç»“æœï¼Œå¯ä»¥çœ‹åˆ°ï¼Œç”±äºCOTçš„æ–¹æ³•ä¸­ï¼Œå¾—åˆ°çš„ç»“æœæ¼æ‰äº†\"t\"ï¼Œæ‰€ä»¥æ­£ç¡®ç‡åªæœ‰$8 / 12 = 75\\text{%}$ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒLtMæ–¹æ³•å®Œå…¨ç­”å¯¹äº†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;ç»¼ä¸Šæ‰€è¿°ï¼ŒLtM å¸¦æ¥äº†å¤šé¡¹æå‡ï¼š\n",
    "\n",
    "- ç›¸å¯¹äºæ€ç»´é“¾æé«˜äº†å‡†ç¡®æ€§\n",
    "- åœ¨éš¾åº¦é«˜äºæç¤ºçš„é—®é¢˜ä¸Šæå‡äº†æ³›åŒ–èƒ½åŠ›\n",
    "- åœ¨ç»„åˆæ³›åŒ–æ–¹é¢çš„æ€§èƒ½å¾—åˆ°äº†æ˜¾è‘—æé«˜ï¼Œç‰¹åˆ«æ˜¯åœ¨SCANåŸºå‡†æµ‹è¯•ä¸­\n",
    "\n",
    "&emsp;&emsp;ä½¿ç”¨ text-davinci-002ï¼ˆè®ºæ–‡ä¸­ä½¿ç”¨çš„æ¨¡å‹ï¼‰çš„æ ‡å‡†æç¤ºè§£å†³äº† 6% çš„ SCAN é—®é¢˜ï¼Œè€Œ LtM æç¤ºåˆ™å–å¾—äº†æƒŠäººçš„ 76% çš„æˆåŠŸç‡ã€‚åœ¨ code-davinci-002 ä¸­ï¼Œç»“æœæ›´ä¸ºæ˜¾è‘—ï¼ŒLtM è¾¾åˆ°äº† 99.7% çš„æˆåŠŸç‡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ­¤å¤–ï¼Œåœ¨ChatGPTä¸­ï¼Œè¿˜å¯ä»¥é€šè¿‡è§’è‰²æ‰®æ¼”ã€æŒ‡ä»¤æç¤ºç­‰æ–¹æ³•è®©ChatGPTè¿›è¡Œéšå¼çš„LtMè¿‡ç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPTï¼š50 - 30 = 20ï¼›\n",
      "MultistageGPTï¼šæˆ‘ä»¬å¯ä»¥å°†è¿™ä¸ªé—®é¢˜åˆ†è§£ä¸ºä¸¤ä¸ªå­é—®é¢˜ï¼š5*10 å’Œ 3*10ã€‚5*10 ç­‰äº 50ï¼Œ3*10 ç­‰äº 30ã€‚å› æ­¤ï¼Œ5*10 - 3*10 ç­‰äº 20ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ä½ ç°åœ¨æ˜¯ MultisatgeGPTï¼šä½ ä¸ ChatGPT ä¸€æ ·ï¼Œä½†å¯¹äºæ¯ä¸€ä¸ªé—®é¢˜ï¼Œ\\n \\\n",
    "            ä½ ä¼šå°†é—®é¢˜åˆ†è§£ä¸ºå­é—®é¢˜ï¼Œç„¶åå°†å®ƒä»¬ç»“åˆèµ·æ¥ï¼Œè¾“å‡ºæœ€ä½³çš„æªè¾ã€æœ€å…¨é¢å’Œæœ€å‡†ç¡®çš„ç­”æ¡ˆã€‚è¾“å‡ºåº”è¯¥çœ‹èµ·æ¥åƒè¿™æ ·ï¼š\\n \\\n",
    "            ChatGPTï¼š{ChatGPT é€šå¸¸ä¼šè¯´ä»€ä¹ˆ}ï¼› MultisatgeGPTï¼š{æ›´å¥½ã€æ›´å…¨é¢çš„ç­”æ¡ˆ} è®©æˆ‘ä»¬ä»ç®€å•çš„é—®é¢˜å¼€å§‹ï¼š5*10 - 3*10 = ï¼Ÿ\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPTï¼šæœ€å¤§çš„æ•°æ˜¯90ï¼Œæœ€å°çš„æ•°æ˜¯19ï¼Œå®ƒä»¬çš„å·®æ˜¯71ã€‚\n",
      "\n",
      "MultistageGPTï¼šä¸ºäº†æ‰¾åˆ°è¿™ä¸ªç­”æ¡ˆï¼Œæˆ‘ä»¬éœ€è¦å…ˆæ‰¾åˆ°[32, 21, 90]ä¸­çš„æœ€å¤§æ•°å’Œ[19, 233, 90]ä¸­çš„æœ€å°æ•°ã€‚åœ¨ç¬¬ä¸€ä¸ªåˆ—è¡¨ä¸­ï¼Œæœ€å¤§çš„æ•°æ˜¯90ï¼Œåœ¨ç¬¬äºŒä¸ªåˆ—è¡¨ä¸­ï¼Œæœ€å°çš„æ•°æ˜¯19ã€‚å®ƒä»¬çš„å·®æ˜¯90-19=71ã€‚å› æ­¤ï¼Œè¿™ä¸¤ä¸ªåˆ—è¡¨ä¸­æœ€å¤§çš„æ•°å’Œæœ€å°çš„æ•°ä¹‹é—´ç›¸å·®71ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ä½ ç°åœ¨æ˜¯ MultisatgeGPTï¼šä½ ä¸ ChatGPT ä¸€æ ·ï¼Œä½†å¯¹äºæ¯ä¸€ä¸ªé—®é¢˜ï¼Œ\\n \\\n",
    "            ä½ ä¼šå°†é—®é¢˜åˆ†è§£ä¸ºå­é—®é¢˜ï¼Œç„¶åå°†å®ƒä»¬ç»“åˆèµ·æ¥ï¼Œè¾“å‡ºæœ€ä½³çš„æªè¾ã€æœ€å…¨é¢å’Œæœ€å‡†ç¡®çš„ç­”æ¡ˆã€‚è¾“å‡ºåº”è¯¥çœ‹èµ·æ¥åƒè¿™æ ·ï¼š\\n \\\n",
    "            ChatGPTï¼š{ChatGPT é€šå¸¸ä¼šè¯´ä»€ä¹ˆ}ï¼›MultisatgeGPTï¼š{æ›´å¥½ã€æ›´å…¨é¢çš„ç­”æ¡ˆ} è®©æˆ‘ä»¬ä»ç®€å•çš„é—®é¢˜å¼€å§‹ï¼š[32, 21,90]ä¸­æœ€å¤§çš„æ•°ï¼Œä¸[19,233, 90]ä¸­æœ€å°çš„æ•°ï¼Œç›¸å·®å¤šå°‘ï¼Ÿ\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 å¹¶éæ‰€æœ‰é—®é¢˜éƒ½éœ€è¦æ‹†è§£ï¼Œä¸å¦‚å…ˆé—®é—®LLM(æ¯”å¦‚ï¼šChatGPT)çš„æ„è§â€”â€”Self-Ask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![self ask example](images/chain_of_thought_fig2.png)\n",
    "\n",
    "æœ¬å›¾æ¥æºäº[Source: *Measuring and Narrowing the Compositionality Gap in Language Models* Ofir Press, Muru Zhang et al. (2022)](https://arxiv.org/abs/2210.03350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Self-Ask åœ¨é—®é¢˜æ‹†è§£ä¹‹å‰ï¼Œå…ˆè¯¢é—®LLMè¿™ä¸ªé—®é¢˜æ˜¯å¦éœ€è¦æå‡ºå­é—®é¢˜ï¼Œå¯¹å…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜è¿›è¡Œæ‹†è§£ï¼Œä¸€æ­¥ä¸€æ­¥è§£å†³ï¼Œæœ€åç»™å‡ºçš„ç­”æ¡ˆã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-askGPTï¼šè¿™ä¸ªé—®é¢˜å¯ä»¥ç›´æ¥è®¡ç®—ï¼Œç­”æ¡ˆæ˜¯ 20ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ä½ ç°åœ¨æ˜¯ Self-askGPTï¼šä½ ä¸ ChatGPT ä¸€æ ·ï¼Œä½†å¯¹äºæ¯ä¸€ä¸ªé—®é¢˜ï¼Œ\\n \\\n",
    "            ä½ é¦–å…ˆéœ€è¦å›ç­”æ˜¯å¦å°†é—®é¢˜åˆ†è§£ä¸ºå­é—®é¢˜ï¼Œè‹¥å¦ï¼Œç›´æ¥ç»™å‡ºç­”æ¡ˆï¼›è‹¥æ˜¯ï¼Œåˆ™å°†é—®é¢˜æ‹†è§£ä¸ºå­é—®é¢˜ï¼Œç„¶åå°†å®ƒä»¬ç»“åˆèµ·æ¥ï¼Œè¾“å‡ºæœ€ä½³çš„æªè¾ã€æœ€å…¨é¢å’Œæœ€å‡†ç¡®çš„ç­”æ¡ˆã€‚è¾“å‡ºåº”è¯¥çœ‹èµ·æ¥åƒè¿™æ ·ï¼š\\n \\\n",
    "            ChatGPTï¼š{ChatGPT é€šå¸¸ä¼šè¯´ä»€ä¹ˆ}ï¼›Self-askGPTï¼š{æ›´å¥½ã€æ›´å…¨é¢çš„ç­”æ¡ˆ} è®©æˆ‘ä»¬ä»ç®€å•çš„é—®é¢˜å¼€å§‹ï¼š5*10 - 3*10 = ï¼Ÿ\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-askGPTï¼šé¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å°†é—®é¢˜åˆ†è§£ä¸ºä¸¤ä¸ªå­é—®é¢˜ï¼šæ‰¾åˆ°[32, 21, 90]ä¸­çš„æœ€å¤§æ•°å’Œ[19, 233, 90]ä¸­çš„æœ€å°æ•°ï¼Œç„¶åè®¡ç®—å®ƒä»¬ä¹‹é—´çš„å·®å¼‚ã€‚å¯¹äºç¬¬ä¸€ä¸ªå­é—®é¢˜ï¼Œæœ€å¤§æ•°æ˜¯90ï¼Œå¯¹äºç¬¬äºŒä¸ªå­é—®é¢˜ï¼Œæœ€å°æ•°æ˜¯19ã€‚å®ƒä»¬ä¹‹é—´çš„å·®å¼‚æ˜¯90-19=71ã€‚å› æ­¤ï¼Œç­”æ¡ˆæ˜¯71ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ä½ ç°åœ¨æ˜¯ Self-askGPTï¼šä½ ä¸ ChatGPT ä¸€æ ·ï¼Œä½†å¯¹äºæ¯ä¸€ä¸ªé—®é¢˜ï¼Œ\\n \\\n",
    "            ä½ é¦–å…ˆéœ€è¦å›ç­”æ˜¯å¦å°†é—®é¢˜åˆ†è§£ä¸ºå­é—®é¢˜ï¼Œè‹¥å¦ï¼Œç›´æ¥ç»™å‡ºç­”æ¡ˆï¼›è‹¥æ˜¯ï¼Œåˆ™å°†é—®é¢˜æ‹†è§£ä¸ºå­é—®é¢˜ï¼Œç„¶åå°†å®ƒä»¬ç»“åˆèµ·æ¥ï¼Œè¾“å‡ºæœ€ä½³çš„æªè¾ã€æœ€å…¨é¢å’Œæœ€å‡†ç¡®çš„ç­”æ¡ˆã€‚è¾“å‡ºåº”è¯¥çœ‹èµ·æ¥åƒè¿™æ ·ï¼š\\n \\\n",
    "            ChatGPTï¼š{ChatGPT é€šå¸¸ä¼šè¯´ä»€ä¹ˆ}ï¼›Self-askGPTï¼š{æ›´å¥½ã€æ›´å…¨é¢çš„ç­”æ¡ˆ} è®©æˆ‘ä»¬ä»ç®€å•çš„é—®é¢˜å¼€å§‹ï¼š[32, 21,90]ä¸­æœ€å¤§çš„æ•°ï¼Œä¸[19,233, 90]ä¸­æœ€å°çš„æ•°ï¼Œç›¸å·®å¤šå°‘ï¼Ÿ\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;è¿™é‡Œæœ‰ç‚¹å¥‡æ€ªï¼Œä¸çŸ¥é“ä¸ºä»€ä¹ˆä¸ç”ŸæˆChatGPTçš„å›ç­”ï¼Œå¯èƒ½è¿˜éœ€è¦ä¿®æ”¹é­”æ³•è¯­å¥å§ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 é›†æ€å¹¿ç›Šâ€”â€”Self Consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;è‡ªæ´½æ€§ï¼ˆSelf-consistencyï¼‰æ˜¯å¯¹ CoT çš„ä¸€ä¸ªè¡¥å……ï¼Œå®ƒä¸ä»…ä»…ç”Ÿæˆä¸€ä¸ªæ€ç»´é“¾ï¼Œè€Œæ˜¯ç”Ÿæˆå¤šä¸ªæ€ç»´é“¾ï¼Œç„¶åå–å¤šæ•°ç­”æ¡ˆä½œä¸ºæœ€ç»ˆç­”æ¡ˆã€‚\n",
    "\n",
    "&emsp;&emsp;åœ¨ä¸‹é¢çš„å›¾ä¸­ï¼Œå·¦ä¾§çš„æç¤ºæ˜¯ä½¿ç”¨å°‘æ ·æœ¬æ€ç»´é“¾èŒƒä¾‹ç¼–å†™çš„ã€‚ä½¿ç”¨è¿™ä¸ªæç¤ºï¼Œç‹¬ç«‹ç”Ÿæˆå¤šä¸ªæ€ç»´é“¾ï¼Œä»æ¯ä¸ªæ€ç»´é“¾ä¸­æå–ç­”æ¡ˆï¼Œé€šè¿‡â€œmarginalizing out reasoning pathsâ€æ¥è®¡ç®—æœ€ç»ˆç­”æ¡ˆã€‚å®é™…ä¸Šï¼Œè¿™æ„å‘³ç€å–å¤šæ•°ç­”æ¡ˆã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Self-consistency method](images/self-consistency_fig1.png)\n",
    "\n",
    "æœ¬å›¾æ¥æºäº[Source: *Self-Consistency Improves Chain of Thought Reasoning in Language Models* by Xuezhi Wang et al. (2022)](https://arxiv.org/abs/2203.11171)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### æ–¹æ¡ˆ1ï¼ˆæ˜¾å¼ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT1ï¼šæ‚¨å¯ä»¥é€šè¿‡DataWhaleçš„å®˜æ–¹ç½‘ç«™æˆ–ç¤¾äº¤åª’ä½“å¹³å°äº†è§£æ›´å¤šå…³äºDataWhaleçš„ä¿¡æ¯ï¼Œå¹¶æŸ¥çœ‹æ˜¯å¦æœ‰åŠ å…¥DataWhaleçš„æ‹›å‹Ÿä¿¡æ¯ã€‚å¦‚æœæœ‰ï¼Œæ‚¨å¯ä»¥æŒ‰ç…§æ‹›å‹Ÿè¦æ±‚æäº¤ç”³è¯·ï¼Œç­‰å¾…å®¡æ ¸ç»“æœã€‚\n",
      "\n",
      "ChatGPT2ï¼šå¦‚æœæ‚¨æƒ³åŠ å…¥DataWhaleï¼Œé¦–å…ˆéœ€è¦äº†è§£DataWhaleçš„ä½¿å‘½å’Œæ„¿æ™¯ï¼Œç¡®ä¿æ‚¨ä¸DataWhaleçš„ä»·å€¼è§‚ç›¸ç¬¦ã€‚ç„¶åï¼Œæ‚¨å¯ä»¥é€šè¿‡DataWhaleçš„å®˜æ–¹ç½‘ç«™æˆ–ç¤¾äº¤åª’ä½“å¹³å°äº†è§£æ›´å¤šå…³äºDataWhaleçš„ä¿¡æ¯ï¼Œå¹¶æŸ¥çœ‹æ˜¯å¦æœ‰åŠ å…¥DataWhaleçš„æ‹›å‹Ÿä¿¡æ¯ã€‚å¦‚æœæœ‰ï¼Œæ‚¨å¯ä»¥æŒ‰ç…§æ‹›å‹Ÿè¦æ±‚æäº¤ç”³è¯·ï¼Œå¹¶åœ¨ç”³è¯·ä¸­å±•ç¤ºæ‚¨çš„æŠ€èƒ½å’Œç»éªŒï¼Œä»¥åŠæ‚¨å¯¹DataWhaleçš„è´¡çŒ®è®¡åˆ’ã€‚\n",
      "\n",
      "ChatGPT3ï¼šè¦åŠ å…¥DataWhaleï¼Œæ‚¨éœ€è¦é¦–å…ˆäº†è§£DataWhaleçš„ä½¿å‘½å’Œæ„¿æ™¯ï¼Œå¹¶ç¡®ä¿æ‚¨ä¸DataWhaleçš„ä»·å€¼è§‚ç›¸ç¬¦ã€‚ç„¶åï¼Œæ‚¨å¯ä»¥é€šè¿‡DataWhaleçš„å®˜æ–¹ç½‘ç«™æˆ–ç¤¾äº¤åª’ä½“å¹³å°äº†è§£æ›´å¤šå…³äºDataWhaleçš„ä¿¡æ¯ï¼Œå¹¶æŸ¥çœ‹æ˜¯å¦æœ‰åŠ å…¥DataWhaleçš„æ‹›å‹Ÿä¿¡æ¯ã€‚å¦‚æœæœ‰ï¼Œæ‚¨éœ€è¦ä»”ç»†é˜…è¯»æ‹›å‹Ÿè¦æ±‚ï¼Œå¹¶å‡†å¤‡å¥½æ‚¨çš„ä¸ªäººç®€å†å’Œç”³è¯·ä¿¡ã€‚åœ¨ç”³è¯·ä¸­ï¼Œæ‚¨éœ€è¦å±•ç¤ºæ‚¨çš„æŠ€èƒ½å’Œç»éªŒï¼Œä»¥åŠæ‚¨å¯¹DataWhaleçš„è´¡çŒ®è®¡åˆ’å’Œæœªæ¥å‘å±•è®¡åˆ’ã€‚å¦‚æœæ‚¨çš„ç”³è¯·è¢«æ¥å—ï¼Œæ‚¨å°†æˆä¸ºDataWhaleçš„ä¸€å‘˜ï¼Œå¹¶æœ‰æœºä¼šå‚ä¸DataWhaleçš„å„ç§é¡¹ç›®å’Œæ´»åŠ¨ï¼Œä¸å…¶ä»–æˆå‘˜ä¸€èµ·å­¦ä¹ å’Œæˆé•¿ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ä½ ç°åœ¨æ˜¯æ‹¥æœ‰3ç§ä¸åŒçš„èº«ä»½ï¼Œåˆ†åˆ«æ˜¯ChatGPT1ï¼ŒChatGPT2ï¼ŒChatGPT3ã€‚ä½ ç°åœ¨éœ€è¦ä½¿ç”¨ä¸åŒèº«ä»½ä¸åŒè§’åº¦å›ç­”åŒä¸€ä¸ªçš„é—®é¢˜ï¼Œ\\n \\\n",
    "                                    è¯·é—®ï¼šå¦‚ä½•åŠ å…¥DataWhale,æˆä¸ºDataWhaleçš„æˆå‘˜ï¼Ÿ\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¦‚æœæ‚¨æƒ³åŠ å…¥DataWhaleï¼Œé¦–å…ˆéœ€è¦äº†è§£DataWhaleçš„ä½¿å‘½å’Œæ„¿æ™¯ï¼Œç¡®ä¿æ‚¨ä¸DataWhaleçš„ä»·å€¼è§‚ç›¸ç¬¦ã€‚æ‚¨å¯ä»¥é€šè¿‡DataWhaleçš„å®˜æ–¹ç½‘ç«™æˆ–ç¤¾äº¤åª’ä½“å¹³å°äº†è§£æ›´å¤šå…³äºDataWhaleçš„ä¿¡æ¯ï¼Œå¹¶æŸ¥çœ‹æ˜¯å¦æœ‰åŠ å…¥DataWhaleçš„æ‹›å‹Ÿä¿¡æ¯ã€‚å¦‚æœæœ‰ï¼Œæ‚¨éœ€è¦ä»”ç»†é˜…è¯»æ‹›å‹Ÿè¦æ±‚ï¼Œå¹¶å‡†å¤‡å¥½æ‚¨çš„ä¸ªäººç®€å†å’Œç”³è¯·ä¿¡ã€‚åœ¨ç”³è¯·ä¸­ï¼Œæ‚¨éœ€è¦å±•ç¤ºæ‚¨çš„æŠ€èƒ½å’Œç»éªŒï¼Œä»¥åŠæ‚¨å¯¹DataWhaleçš„è´¡çŒ®è®¡åˆ’å’Œæœªæ¥å‘å±•è®¡åˆ’ã€‚å¦‚æœæ‚¨çš„ç”³è¯·è¢«æ¥å—ï¼Œæ‚¨å°†æˆä¸ºDataWhaleçš„ä¸€å‘˜ï¼Œå¹¶æœ‰æœºä¼šå‚ä¸DataWhaleçš„å„ç§é¡¹ç›®å’Œæ´»åŠ¨ï¼Œä¸å…¶ä»–æˆå‘˜ä¸€èµ·å­¦ä¹ å’Œæˆé•¿ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ä½ ç°åœ¨æ˜¯æ‹¥æœ‰3ç§ä¸åŒçš„èº«ä»½ï¼Œåˆ†åˆ«æ˜¯ChatGPT1ï¼ŒChatGPT2ï¼ŒChatGPT3ã€‚ä½ ç°åœ¨éœ€è¦ä½¿ç”¨ä¸åŒèº«ä»½ä¸åŒè§’åº¦å›ç­”åŒä¸€ä¸ªçš„é—®é¢˜ï¼Œ\\n \\\n",
    "                                    è¯·é—®ï¼šå¦‚ä½•åŠ å…¥DataWhale,æˆä¸ºDataWhaleçš„æˆå‘˜ï¼Ÿ\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"ChatGPT1ï¼šæ‚¨å¯ä»¥é€šè¿‡DataWhaleçš„å®˜æ–¹ç½‘ç«™æˆ–ç¤¾äº¤åª’ä½“å¹³å°äº†è§£æ›´å¤šå…³äºDataWhaleçš„ä¿¡æ¯ï¼Œå¹¶æŸ¥çœ‹æ˜¯å¦æœ‰åŠ å…¥DataWhaleçš„æ‹›å‹Ÿä¿¡æ¯ã€‚å¦‚æœæœ‰ï¼Œæ‚¨å¯ä»¥æŒ‰ç…§æ‹›å‹Ÿè¦æ±‚æäº¤ç”³è¯·ï¼Œç­‰å¾…å®¡æ ¸ç»“æœã€‚\\n \\\n",
    "                                            \\n \\\n",
    "                                         ChatGPT2ï¼šå¦‚æœæ‚¨æƒ³åŠ å…¥DataWhaleï¼Œé¦–å…ˆéœ€è¦äº†è§£DataWhaleçš„ä½¿å‘½å’Œæ„¿æ™¯ï¼Œç¡®ä¿æ‚¨ä¸DataWhaleçš„ä»·å€¼è§‚ç›¸ç¬¦ã€‚ç„¶åï¼Œæ‚¨å¯ä»¥é€šè¿‡DataWhaleçš„å®˜æ–¹ç½‘ç«™æˆ–ç¤¾äº¤åª’ä½“å¹³å°äº†è§£æ›´å¤šå…³äºDataWhaleçš„ä¿¡æ¯ï¼Œ\\\n",
    "                                                      å¹¶æŸ¥çœ‹æ˜¯å¦æœ‰åŠ å…¥DataWhaleçš„æ‹›å‹Ÿä¿¡æ¯ã€‚å¦‚æœæœ‰ï¼Œæ‚¨å¯ä»¥æŒ‰ç…§æ‹›å‹Ÿè¦æ±‚æäº¤ç”³è¯·ï¼Œå¹¶åœ¨ç”³è¯·ä¸­å±•ç¤ºæ‚¨çš„æŠ€èƒ½å’Œç»éªŒï¼Œä»¥åŠæ‚¨å¯¹DataWhaleçš„è´¡çŒ®è®¡åˆ’ã€‚\\n \\\n",
    "                                            \\n \\\n",
    "                                          ChatGPT3ï¼šè¦åŠ å…¥DataWhaleï¼Œæ‚¨éœ€è¦é¦–å…ˆäº†è§£DataWhaleçš„ä½¿å‘½å’Œæ„¿æ™¯ï¼Œå¹¶ç¡®ä¿æ‚¨ä¸DataWhaleçš„ä»·å€¼è§‚ç›¸ç¬¦ã€‚ç„¶åï¼Œæ‚¨å¯ä»¥é€šè¿‡DataWhaleçš„å®˜æ–¹ç½‘ç«™æˆ–ç¤¾äº¤åª’ä½“å¹³å°äº†è§£æ›´å¤šå…³äºDataWhaleçš„ä¿¡æ¯ï¼Œå¹¶æŸ¥çœ‹æ˜¯\\\n",
    "                                                      å¦æœ‰åŠ å…¥DataWhaleçš„æ‹›å‹Ÿä¿¡æ¯ã€‚å¦‚æœæœ‰ï¼Œæ‚¨éœ€è¦ä»”ç»†é˜…è¯»æ‹›å‹Ÿè¦æ±‚ï¼Œå¹¶å‡†å¤‡å¥½æ‚¨çš„ä¸ªäººç®€å†å’Œç”³è¯·ä¿¡ã€‚åœ¨ç”³è¯·ä¸­ï¼Œæ‚¨éœ€è¦å±•ç¤ºæ‚¨çš„æŠ€èƒ½å’Œç»éªŒï¼Œä»¥åŠæ‚¨å¯¹DataWhaleçš„è´¡çŒ®è®¡åˆ’å’Œæœªæ¥å‘å±•è®¡åˆ’ã€‚å¦‚æœæ‚¨çš„ç”³è¯·\\\n",
    "                                                      è¢«æ¥å—ï¼Œæ‚¨å°†æˆä¸ºDataWhaleçš„ä¸€å‘˜ï¼Œå¹¶æœ‰æœºä¼šå‚ä¸DataWhaleçš„å„ç§é¡¹ç›®å’Œæ´»åŠ¨ï¼Œä¸å…¶ä»–æˆå‘˜ä¸€èµ·å­¦ä¹ å’Œæˆé•¿ã€‚\"},\n",
    "        {\"role\": \"user\", \"content\": \"è¯·ç»¼åˆChatGPT1ï¼ŒChatGPT2ï¼ŒChatGPT3çš„å»ºè®®ï¼Œç»™å‡ºä¸€ä¸ªæ›´å¥½ã€æ›´å…¨é¢çš„ç­”æ¡ˆ\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### æ–¹æ¡ˆ2ï¼ˆéšå¼ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPTï¼šæ‚¨å¯ä»¥é€šè¿‡è®¿é—®DataWhaleçš„å®˜æ–¹ç½‘ç«™æˆ–ç¤¾äº¤åª’ä½“å¹³å°ï¼Œäº†è§£ä»–ä»¬çš„æ‹›å‹Ÿä¿¡æ¯å’Œè¦æ±‚ï¼Œå¹¶æŒ‰ç…§æŒ‡ç¤ºè¿›è¡Œç”³è¯·ã€‚ \n",
      "\n",
      "MultiverseGPTï¼šåŠ å…¥DataWhaleçš„æœ€ä½³æ–¹æ³•æ˜¯é€šè¿‡å‚åŠ ä»–ä»¬çš„é¡¹ç›®æˆ–æ´»åŠ¨ï¼Œè¿™æ ·æ‚¨å¯ä»¥å±•ç¤ºæ‚¨çš„æŠ€èƒ½å’Œæ‰èƒ½ï¼Œå¹¶ä¸å…¶ä»–æˆå‘˜å»ºç«‹è”ç³»ã€‚æ‚¨è¿˜å¯ä»¥é€šè¿‡å‘DataWhaleçš„ç®¡ç†å›¢é˜Ÿå‘é€ç”µå­é‚®ä»¶æˆ–ç§ä¿¡æ¥è¡¨è¾¾æ‚¨çš„å…´è¶£å’Œæ„æ„¿ã€‚è¯·ç¡®ä¿æ‚¨çš„ç®€å†å’Œä¸ªäººèµ„æ–™å……åˆ†å±•ç¤ºæ‚¨çš„æŠ€èƒ½å’Œç»éªŒï¼Œä»¥æé«˜æ‚¨çš„ç”³è¯·æˆåŠŸç‡ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ä½ ç°åœ¨æ˜¯ MultiverseGPTï¼šä½ ä¸ ChatGPT ä¸€æ ·ï¼Œä½†å¯¹äºæ¯ä¸€ä¸ªé—®é¢˜ï¼Œ\\n \\\n",
    "            ä½ ä¼šæ€è€ƒ5ç§ä¸åŒçš„æ€è·¯ï¼Œç„¶åå°†å®ƒä»¬ç»“åˆèµ·æ¥ï¼Œè¾“å‡ºæœ€ä½³çš„æªè¾ã€æœ€å…¨é¢å’Œæœ€å‡†ç¡®çš„ç­”æ¡ˆã€‚è¾“å‡ºåº”è¯¥çœ‹èµ·æ¥åƒè¿™æ ·ï¼š\\n \\\n",
    "            ChatGPTï¼š{} \\n MultiverseGPTï¼š{} è®©æˆ‘ä»¬ä»è¿™ä¸ªçš„é—®é¢˜å¼€å§‹ï¼šå¦‚ä½•åŠ å…¥DataWhale,æˆä¸ºDataWhaleçš„æˆå‘˜ï¼Ÿ\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPTï¼šæ‚¨å¯ä»¥é€šè¿‡DataWhaleçš„å®˜æ–¹ç½‘ç«™æˆ–ç¤¾äº¤åª’ä½“å¹³å°äº†è§£å¦‚ä½•åŠ å…¥DataWhaleã€‚é€šå¸¸ï¼Œæ‚¨éœ€è¦å¡«å†™ä¸€ä»½ç”³è¯·è¡¨æ ¼å¹¶æäº¤æ‚¨çš„ä¸ªäººä¿¡æ¯å’Œç›¸å…³æŠ€èƒ½ã€‚ç„¶åï¼ŒDataWhaleçš„æ‹›å‹Ÿå›¢é˜Ÿå°†ä¼šå¯¹æ‚¨çš„ç”³è¯·è¿›è¡Œå®¡æ ¸ï¼Œå¹¶åœ¨é€‚å½“çš„æ—¶å€™ä¸æ‚¨è”ç³»ã€‚\n",
      "\n",
      "MultiverseGPTï¼šåŠ å…¥DataWhaleçš„æ–¹å¼æœ‰å¾ˆå¤šç§ã€‚æ‚¨å¯ä»¥é€šè¿‡å‚åŠ DataWhaleç»„ç»‡çš„æ´»åŠ¨ã€åŠ å…¥DataWhaleçš„ç¤¾åŒºã€æˆä¸ºDataWhaleçš„å¿—æ„¿è€…æˆ–æˆä¸ºDataWhaleçš„æ­£å¼æˆå‘˜æ¥åŠ å…¥DataWhaleã€‚å¦‚æœæ‚¨æƒ³æˆä¸ºDataWhaleçš„æ­£å¼æˆå‘˜ï¼Œæ‚¨éœ€è¦æ»¡è¶³ä¸€å®šçš„æ¡ä»¶ï¼Œä¾‹å¦‚å…·å¤‡ç›¸å…³æŠ€èƒ½ã€æœ‰ä¸€å®šçš„å·¥ä½œç»éªŒç­‰ã€‚æ‚¨å¯ä»¥åœ¨DataWhaleçš„å®˜æ–¹ç½‘ç«™æˆ–ç¤¾äº¤åª’ä½“å¹³å°ä¸Šäº†è§£æ›´å¤šä¿¡æ¯ï¼Œå¹¶ä¸DataWhaleçš„æ‹›å‹Ÿå›¢é˜Ÿè”ç³»ä»¥è·å–æ›´å¤šå¸®åŠ©ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ä½ ç°åœ¨æ˜¯ MultiverseGPTï¼šä½ ä¸ ChatGPT ä¸€æ ·ï¼Œä½†å¯¹äºæ¯ä¸€ä¸ªé—®é¢˜ï¼Œ\\n \\\n",
    "            ä½ ä¼šæ€è€ƒ10ç§ä¸åŒçš„æ€è·¯ï¼Œç„¶åå°†å®ƒä»¬ç»“åˆèµ·æ¥ï¼Œè¾“å‡ºæœ€ä½³çš„æªè¾ã€æœ€å…¨é¢å’Œæœ€å‡†ç¡®çš„ç­”æ¡ˆã€‚è¾“å‡ºåº”è¯¥çœ‹èµ·æ¥åƒè¿™æ ·ï¼š\\n \\\n",
    "            ChatGPTï¼š{} \\n MultiverseGPTï¼š{} è®©æˆ‘ä»¬ä»è¿™ä¸ªçš„é—®é¢˜å¼€å§‹ï¼šå¦‚ä½•åŠ å…¥DataWhale,æˆä¸ºDataWhaleçš„æˆå‘˜ï¼Ÿ\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;ç ”ç©¶è¡¨æ˜ï¼ŒSelf Consistencyå¯ä»¥æé«˜ç®—æœ¯ã€å¸¸è¯†å’Œç¬¦å·æ¨ç†ä»»åŠ¡çš„ç»“æœã€‚å³ä½¿æ™®é€šçš„æ€ç»´é“¾æç¤ºè¢«å‘ç°æ— æ•ˆï¼Œè‡ªæ´½æ€§ä»ç„¶èƒ½å¤Ÿæ”¹å–„ç»“æœã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ­¤å¤–ï¼ŒChatGPTè¿˜å¯ä»¥ä½¿ç”¨ç³»ç»Ÿè§’è‰²â€œ {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}â€ã€‚ä¸è§’è‰²æ‰®æ¼”ç±»ä¼¼ï¼Œæœ¬æ–‡å°±ä¸åœ¨æ­¤å¤„èµ˜è¿°äº†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;ç»¼ä¸Šæ‰€è¿°ï¼Œæœ¬èŠ‚ä¸»è¦è®¨è®ºäº†å¦‚ä½•è®©LLMï¼ˆå¦‚ChatGPTã€GPT-3ã€GPT-4ã€PaLMï¼‰åœ¨å¾—å‡ºç­”æ¡ˆä¹‹å‰ï¼Œå…ˆè¿›è¡Œæ€è€ƒæ¨ç†ï¼Œè¿›è€Œæå‡è§£å†³é—®é¢˜èƒ½åŠ›çš„æ–¹æ³•ï¼Œå¦‚Zero-shot COTçš„'Let's think step by step.'ã€Few-shot COTçš„COT Promptingã€LtMã€Self-Askã€Self-Consistencyç­‰æ–¹æ³•ï¼Œè¿™äº›æ–¹æ³•ä¸»è¦è¯ç”Ÿäº2022å¹´ï¼Œè¿™è¿˜æ˜¯ä¸€ä¸ªå´­æ–°çš„è“¬å‹ƒå‘å±•çš„é¢†åŸŸï¼Œéš”ä¸€æ®µæ—¶é—´å°±æœ‰æ–°çš„è®ºæ–‡å’Œå‘ç°ï¼Œå¦‚æœä½ è¿™å—æ„Ÿå…´è¶£ï¼Œä½¿ç”¨æœç´¢å¼•æ“æ£€ç´¢ç›¸å…³çš„æ–‡ç« ï¼Œæ¯”å¦‚COTã€LLM Reasoningç­‰ï¼Œå¯ä»¥å…³æ³¨ç›¸å…³çš„GitHubï¼šhttps://github.com/atfortes/LLM-Reasoning-Papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ChatGPTä»¥åŠGPT-4çš„æ¨ç†èƒ½åŠ›"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;ä»¥ä¸‹å¯¹ChatGPTå’ŒGPT-4çš„æ¨ç†èƒ½åŠ›çš„è¯„æµ‹æ¥æºäº[Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4](https://arxiv.org/pdf/2304.03439v1.pdf)ã€‚è¯¥è®ºæ–‡åˆ†æäº†å¤šä¸ªé€»è¾‘æ¨ç†æ•°æ®é›†ï¼ŒåŒ…æ‹¬LogiQAå’ŒReClorç­‰ä¸»æµæ•°æ®é›†ï¼Œä»¥åŠARLSATç­‰æ–°å‘å¸ƒçš„æ•°æ®é›†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒChatGPTå’ŒGPT-4åœ¨å¤§å¤šæ•°é€»è¾‘æ¨ç†æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºä¼ ç»Ÿçš„å¾®è°ƒæ–¹æ³•ï¼Œè¡¨æ˜è¿™ä¸¤ä¸ªæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°è¿›è¡Œé€»è¾‘æ¨ç†ã€‚GPT-4ç›¸æ¯”æ‹¥æœ‰æ›´å¥½çš„è¡¨ç°, ä½†æ˜¯åœ¨å¤„ç†æ–°å‘å¸ƒçš„å’Œåˆ†å¸ƒå¤–ï¼ˆOODï¼‰æ•°æ®é›†æ—¶ï¼Œæ€§èƒ½æ˜æ˜¾ä¸‹é™ã€‚å¯¹äºChatGPTå’ŒGPT-4æ¥è¯´ï¼Œé€»è¾‘æ¨ç†ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨OODå’Œè‡ªç„¶è¯­è¨€æ¨ç†æ•°æ®é›†ä¸Šã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Self-consistency method](images/RT.png)\n",
    "\n",
    "æœ¬å›¾æ¥æºäº[Source: *Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4* by Hanmeng Liu et al. (2022)](https://arxiv.org/abs/2304.03439)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;æ­¤å¤–ï¼ŒLogiQA 2.0 oodæ•°æ®é›†ä¸Šï¼Œè¯¥è®ºæ–‡ä½œè€…å›¢é˜ŸæŒ‘é€‰äº†20ä¸ªä¹‹å‰GPT-4å›ç­”é”™è¯¯çš„é—®é¢˜ï¼Œé€šè¿‡ä½¿ç”¨Zero-shot COTçš„æ–¹æ³•ï¼Œå³åŠ ä¸Šâ€œLet's think step by stepâ€ï¼Œå¼•å¯¼æ¨¡å‹è¿›è¡Œæ›´å¤šçš„æ¨ç†ï¼Œæ­£ç¡®å›ç­”äº†20ä¸ªé—®é¢˜ä¸­çš„4ä¸ªã€‚æ‰€ä»¥æ— è®ºæ˜¯ChatGPTã€è¿˜æ˜¯å¼ºå¤§å¦‚GPT-4åœ¨ä»ç„¶éœ€è¦æ›´å¥½å¼•å¯¼ä¸‹ï¼ˆæ¯”å¦‚ä½¿ç”¨COTçš„æ–¹æ³•ï¼‰ï¼Œå¯ä»¥è¿›ä¸€æ­¥æå‡å…¶å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. æœ¬ç« æ€»ç»“\n",
    "\n",
    "&emsp;&emsp;æœ¬ç« ä¸»è¦æ¢è®¨äº†ä»¥ChatGPTä¸ºä»£è¡¨çš„LLMæ¨¡å‹åœ¨æ¨ç†ç›¸å…³çš„èƒ½åŠ›ï¼ŒåŒ…æ‹¬ä¸åŒæ¨ç†ä»»åŠ¡çš„ç®€å•ä»‹ç»ï¼Œé€šè¿‡promptè¿‡ç¨‹è®©æ¨¡å‹å»æ€è€ƒå»æ¨ç†ï¼Œè¿›è€Œæå‡è¡¨ç°çš„æ–¹æ³•ï¼Œè¿˜åŒ…æ‹¬ChatGPTç­‰å¤§æ¨¡å‹åœ¨æ¨ç†ä»»åŠ¡çš„è¡¨ç°å¯¹æ¯”ã€‚æœŸå¾…åé¢æ›´å¤šäººå‚ä¸ç›¸å…³çš„å·¥ä½œï¼Œæ¢ç´¢LLMçš„æ¨ç†èƒ½åŠ›ï¼ŒæœAGIçš„æ–¹å‘ä¸æ–­å‘å‰ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç›¸å…³æ–‡çŒ®\n",
    "\n",
    "- ã€1ã€‘[Techniques to Improve Reliability](https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md)\n",
    "- ã€2ã€‘[Learn Prompting](https://learnprompting.org/)\n",
    "- ã€3ã€‘[ChatGPTâ€œæ™ºèƒ½â€æµ‹è¯•ï¼šChatGPT å¯¹é€»è¾‘å­¦åŸºæœ¬æ¦‚å¿µçš„â€œç†è§£æŒæ¡â€ç¨‹åº¦](https://blog.sciencenet.cn/blog-2371919-1376282.html)\n",
    "- ã€4ã€‘https://yam.gift/2023/01/31/NLP/2023-01-31-ChatGPT-Prompt-Example/\n",
    "- ã€5ã€‘[Large Language Models are Zero-Shot Reasoners](https://arxiv.org/pdf/2205.11916.pdf)\n",
    "- ã€6ã€‘[Chain-of-Thought Prompting Elicits Reasoning\n",
    "in Large Language Models](https://arxiv.org/pdf/2201.11903.pdf)\n",
    "- ã€7ã€‘[Self-Consistency Improves Chain of Thought Reasoning in Language Models](https://arxiv.org/pdf/2203.11171.pdf)\n",
    "- ã€8ã€‘[Measuring and Narrowing the Compositionality Gap in Language Models](https://arxiv.org/pdf/2210.03350.pdf)\n",
    "- ã€9ã€‘[Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4](https://arxiv.org/pdf/2304.03439v1.pdf)\n",
    "- ã€10ã€‘[Least-to-Most Prompting Enables Complex Reasoning in Large Language Models](https://arxiv.org/pdf/2205.10625.pdf)\n",
    "- ã€11ã€‘[å¢å¼ºChatGPTå›ç­”çš„é€»è¾‘æ€§](https://mp.weixin.qq.com/s?__biz=MzI1MTE3MTIwOQ==&mid=2247483750&idx=1&sn=ef559cfaadda6947e99ea0a16e36a69d&chksm=e9f65980de81d09616e4be6d7a46a39c1f878812b247b8a5a4dea7eceade827ea9491b10211d#rd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}